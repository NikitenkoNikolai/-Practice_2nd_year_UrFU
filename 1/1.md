## Импорт необходимых библиотек

```python
import torch
import numpy
import time
```

## Задание 1: Создание и манипуляции с тензорами

### 1.1 Создание тензоров

```python
#Создается тензор с размером матрицы 3x4 элемента, заполненный чилами от 0 до 1
tensor_1 = torch.rand((3,4)) 
#Создается тензор с 2 слоями матриц размерами 3x4. Все элементы - 0
tensor_2 = torch.zeros((2,3,4)) 
# Тензор размером 5x5 заполненный единицами
tensor_3 = torch.ones((5,5))
# Сначала создается 1-мерный тензор из чисел 0 до 15 включительно. После этот тензор трансформируем в размерность 4x4 
# По факту просто переводим из 1x16 в 4x4 (Заренее извините, если я некоторые вещи называю не своими именами)
tensor_4 = torch.arange(0,16).reshape(4,4)

#Следующие строки просто для вашего комфортного просмотра результата (Также будет повторятся и в других пунктах)
lst_tensor = [tensor_1, tensor_2, tensor_3, tensor_4]
for i in range(len(lst_tensor)):
    print(f'Вывод {i+1}')
    print(lst_tensor[i])
```

#### Вывод:
```
Вывод 1
tensor([[0.2395, 0.7870, 0.7401, 0.7896],
        [0.5734, 0.2338, 0.3128, 0.9662],
        [0.0896, 0.8370, 0.7336, 0.1947]])
Вывод 2
tensor([[[0., 0., 0., 0.],
         [0., 0., 0., 0.],
         [0., 0., 0., 0.]],

        [[0., 0., 0., 0.],
         [0., 0., 0., 0.],
         [0., 0., 0., 0.]]])
Вывод 3
tensor([[1., 1., 1., 1., 1.],
        [1., 1., 1., 1., 1.],
        [1., 1., 1., 1., 1.],
        [1., 1., 1., 1., 1.],
        [1., 1., 1., 1., 1.]])
Вывод 4
tensor([[ 0,  1,  2,  3],
        [ 4,  5,  6,  7],
        [ 8,  9, 10, 11],
        [12, 13, 14, 15]])
```

### 1.2 Операции с тензорами

```python
tensor_A = torch.rand((3,4))#Из условия А
tensor_B = torch.rand((4,3))#Из условия B
print(f'Тензор А \n {tensor_A}')
print(f'Тензор B \n {tensor_B}')
tensor_A_transpose = tensor_A.transpose(0,1) #Транспонирование А
print(f'Транспонирование тензора A \n {tensor_A_transpose}')
multi_AB = tensor_A.mm(tensor_B) # Матричное умножение A и B
print(f'Матричное умножение A и B \n {multi_AB}')
Btranspose = tensor_B.transpose(0,1) # транспонированный B
multi_A_Btranspose = tensor_A * Btranspose # Поэлементное умножение A и транспонированного B
print(f'транспонированный B \n {Btranspose}')
print(f'Поэлементное умножение A и транспонированного B \n {multi_A_Btranspose}')
sum_A = torch.sum(tensor_A) #сумма всех элементов тензора A
print(f'Вычислите сумму всех элементов тензора A \n {sum_A}')

```

#### Вывод:
```
Тензор А 
 tensor([[0.9666, 0.3297, 0.4372, 0.7688],
        [0.3517, 0.1627, 0.2282, 0.8802],
        [0.0316, 0.7811, 0.2767, 0.2779]])
Тензор B 
 tensor([[0.3806, 0.9090, 0.7039],
        [0.3294, 0.5256, 0.4356],
        [0.2007, 0.6260, 0.9640],
        [0.2518, 0.8301, 0.7948]])
Транспонирование тензора A 
 tensor([[0.9666, 0.3517, 0.0316],
        [0.3297, 0.1627, 0.7811],
        [0.4372, 0.2282, 0.2767],
        [0.7688, 0.8802, 0.2779]])
Матричное умножение A и B 
 tensor([[0.7578, 1.9638, 1.8565],
        [0.4549, 1.2787, 1.2379],
        [0.3949, 0.8432, 0.8501]])
транспонированный B 
 tensor([[0.3806, 0.3294, 0.2007, 0.2518],
        [0.9090, 0.5256, 0.6260, 0.8301],
        [0.7039, 0.4356, 0.9640, 0.7948]])
Поэлементное умножение A и транспонированного B 
 tensor([[0.3679, 0.1086, 0.0877, 0.1936],
        [0.3197, 0.0855, 0.1428, 0.7306],
        [0.0223, 0.3402, 0.2667, 0.2209]])
Вычислите сумму всех элементов тензора A 
 5.4922990798950195
```

### 1.3 Индексация и срезы

```python
tensor555 = torch.randint(0, 10, (5,5,5)) # из условия Задачи
print(f'Изначальный тезор \n{tensor555}')
'''
Сейчас конкретно есть неясноть, так как в условии написано просто Извлеките первую строку. Непонятно первую строку каждого слоя тензора или первую строку 1-го слоя.
Сделал 2 варианта
Можно просто запомнить следующее [слой,сторка,столбец] и у всех по стандарту 0, а если заменить на :, то это значит все индексы раздела
'''
print(f'Все первые строки \n{tensor555[:,0]}')
print(f'Первая строка 1-го слоя\n{tensor555[0,0]}')
# Дальше я буду считать, что нужно выделить объекты для каждого слоя 

print(f'Последний столбец \n{tensor555[:,:,-1]}')
print(f'Подматрицу размером 2x2 из центра тензора \n{tensor555[:,1:4,1:4]}') # в строковом разделе я выбираю все индексы от 1 до 4 невлючительно, аналогично со столбцами
print(f'Все элементы с четными индексами \n {tensor555[::2,::2,::2]}') # Выбираю все индексы с шагом 2 (также выбираю слои), таким образом получаю элемент с чет индеком
```

#### Вывод:
```
Изначальный тезор 
tensor([[[7, 6, 4, 4, 8],
         [4, 6, 4, 8, 0],
         [3, 5, 2, 7, 4],
         [5, 2, 4, 9, 2],
         [8, 0, 5, 4, 6]],

        [[7, 0, 4, 7, 5],
         [4, 5, 0, 2, 1],
         [3, 2, 6, 7, 5],
         [6, 3, 6, 5, 7],
         [1, 4, 2, 8, 4]],

        [[8, 8, 0, 2, 1],
         [9, 4, 3, 9, 1],
         [4, 4, 3, 6, 5],
         [8, 0, 7, 3, 3],
         [6, 5, 7, 6, 2]],

        [[5, 6, 8, 9, 6],
         [5, 8, 2, 2, 7],
         [3, 3, 5, 2, 9],
         [5, 9, 2, 3, 0],
         [2, 5, 7, 5, 7]],

        [[0, 3, 6, 8, 9],
         [7, 6, 5, 6, 1],
         [2, 6, 1, 3, 0],
         [1, 2, 9, 7, 3],
         [9, 0, 8, 4, 9]]])
Все первые строки 
tensor([[7, 6, 4, 4, 8],
        [7, 0, 4, 7, 5],
        [8, 8, 0, 2, 1],
        [5, 6, 8, 9, 6],
        [0, 3, 6, 8, 9]])
Первая строка 1-го слоя
tensor([7, 6, 4, 4, 8])
Последний столбец 
tensor([[8, 0, 4, 2, 6],
        [5, 1, 5, 7, 4],
        [1, 1, 5, 3, 2],
        [6, 7, 9, 0, 7],
        [9, 1, 0, 3, 9]])
Подматрицу размером 2x2 из центра тензора 
tensor([[[6, 4, 8],
         [5, 2, 7],
         [2, 4, 9]],

        [[5, 0, 2],
         [2, 6, 7],
         [3, 6, 5]],

        [[4, 3, 9],
         [4, 3, 6],
         [0, 7, 3]],

        [[8, 2, 2],
         [3, 5, 2],
         [9, 2, 3]],

        [[6, 5, 6],
         [6, 1, 3],
         [2, 9, 7]]])
Все элементы с четными индексами 
 tensor([[[7, 4, 8],
         [3, 2, 4],
         [8, 5, 6]],

        [[8, 0, 1],
         [4, 3, 5],
         [6, 7, 2]],

        [[0, 6, 9],
         [2, 1, 0],
         [9, 8, 9]]])
```

### 1.4 Работа с формами

```python
tensor24 = torch.arange(0,24) # Тензор из условия
print(f'Тензор размером 2x12 \n{tensor24.reshape((2,12))}')
print(f'Тензор размером 3x8 \n{tensor24.reshape((3,8))}')
print(f'Тензор размером 4x6 \n{tensor24.reshape((4,6))}')
print(f'Тензор размером 2x3x4 \n{tensor24.reshape((2,3,4))}')
print(f'Тензор размером 2x2x2x3 \n{tensor24.reshape((2,2,2,3))}')
```

#### Вывод:
```
Тензор размером 2x12 
tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11],
        [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]])
Тензор размером 3x8 
tensor([[ 0,  1,  2,  3,  4,  5,  6,  7],
        [ 8,  9, 10, 11, 12, 13, 14, 15],
        [16, 17, 18, 19, 20, 21, 22, 23]])
Тензор размером 4x6 
tensor([[ 0,  1,  2,  3,  4,  5],
        [ 6,  7,  8,  9, 10, 11],
        [12, 13, 14, 15, 16, 17],
        [18, 19, 20, 21, 22, 23]])
Тензор размером 2x3x4 
tensor([[[ 0,  1,  2,  3],
         [ 4,  5,  6,  7],
         [ 8,  9, 10, 11]],

        [[12, 13, 14, 15],
         [16, 17, 18, 19],
         [20, 21, 22, 23]]])
Тензор размером 2x2x2x3 
tensor([[[[ 0,  1,  2],
          [ 3,  4,  5]],

         [[ 6,  7,  8],
          [ 9, 10, 11]]],


        [[[12, 13, 14],
          [15, 16, 17]],

         [[18, 19, 20],
          [21, 22, 23]]]])
```

## Задание 2: Автоматическое дифференцирование

### 2.1 Простые вычисления с градиентами

```python
x = torch.tensor([0.0,1.0,2.0], requires_grad=True)
y = torch.tensor([3.0,4.0,5.0], requires_grad=True)
z = torch.tensor([6.0,7.0,8.0], requires_grad=True)
function = x**2 + y**2 + z**2 + 2*x*y*z # сама функция

loss = function.sum()#Представление в виде скалярного числа
loss.backward() #Вызываем фунцию backward, чтобы запомнить как получилась function из x,y,z и соответственно для x,y,z высчитывает их производные. Обратное распространение

print(f'производная по x = {x.grad}') #Вызываем градиетны для каждой переменной, которые ранее были высчитаны 
print(f'производная по y = {y.grad}')
print(f'производная по z = {z.grad}')
'''
Аналитический спопсоб решения (По-идее просто показываем как всё это считалось)
df/dx = 2x + 2yz = [2*0+2*3*6, 2*1+2*4*7, 2*2+2*5*8] = [36, 58, 84]
аналогично и с другими
df/dx = 2y + 2xz = [2*3+2*0*6, 2*4+2*1*7, 2*5+2*2*8] = [6, 22, 42]
df/dx = 2z + 2xy = [2*6+2*3*0, 2*7+2*4*1, 2*8+2*5*2] = [12, 22, 36]
'''
```

#### Вывод:
```
производная по x = tensor([36., 58., 84.])
производная по y = tensor([ 6., 22., 42.])
производная по z = tensor([12., 22., 36.])
'\nАналитический спопсоб решения (По-идее просто показываем как всё это считалось)\ndf/dx = 2x + 2yz = [2*0+2*3*6, 2*1+2*4*7, 2*2+2*5*8] = [36, 58, 84]\nаналогично и с другими\ndf/dx = 2y + 2xz = [2*3+2*0*6, 2*4+2*1*7, 2*5+2*2*8] = [6, 22, 42]\ndf/dx = 2z + 2xy = [2*6+2*3*0, 2*7+2*4*1, 2*8+2*5*2] = [12, 22, 36]\n'
```

### 2.2 Градиент функции потерь

```python
x = torch.tensor([1.0, 2.0, 3.0])
y_true = torch.tensor([3.0, 5.0, 7.0]) # представление y = 2x + 1
# вес и смещение устанавливаю по стандарту как 0
w = torch.tensor(0.0, requires_grad=True)
b = torch.tensor(0.0, requires_grad=True)
y_pred = w*x+b 
mse = ((y_pred-y_true)**2).mean() # Судя по документации, в pytorch функция mean уже учитывает сумму и n
mse.backward() #также делаем обратное распространение 
print(f'mse = {mse.item()}')
print(f'градиент w = {w.grad.item()}')
print(f'градиент b = {b.grad.item()}')
```

#### Вывод:
```
mse = 27.66666603088379
градиент w = -22.666667938232422
градиент b = -10.0
```

### 2.3 Цепное правило

```python
x = torch.tensor(2.0, requires_grad=True)
function = torch.sin(x**2 + 1)

# Считаем градиент через backward()
function.backward(retain_graph=True)  # сохраняем граф, без этого иначе почему то ловит ошибку
print(f'df/dx = {x.grad}')

# Проверяем через autograd.grad
df_dx = torch.autograd.grad(function, x)[0]
print(f'Проверка с помощью torch.autograd.grad = {df_dx}')
#результаты совпали
```

#### Вывод:
```
df/dx = 1.1346487998962402
Проверка с помощью torch.autograd.grad = 1.1346487998962402
```

## Задание 3: Сравнение производительности CPU vs CUDA

### 3.1 Подготовка данных

```python
tensor1 = torch.rand((64,1024,1024))
tensor2 = torch.rand((128,512,512))
tensor3 = torch.rand((256,256,256)) # Думаю из предыдущих заданий понятно все, что тут делается
print(f"Tensor 64x1024x1024: {tensor1.shape}")
print(f"Tensor 128x512x512: {tensor2.shape}")
print(f"Tensor 256x256x256: {tensor3.shape}")
```

#### Вывод:
```
Tensor 64x1024x1024: torch.Size([64, 1024, 1024])
Tensor 128x512x512: torch.Size([128, 512, 512])
Tensor 256x256x256: torch.Size([256, 256, 256])
```

### 3.2 Функция измерения времени

```python
def measure_time(fn, device='cpu', num_runs=10):
    '''
    Измеряет время выполнения функции fn.
    Параметры:
        fn: вызываемая функция без аргументов
        device: 'cpu' или 'cuda'
        num_runs: количество прогонов для усреднения
    Возвращает среднее время выполнения в миллисекундах
    '''
    if device == 'cuda': 
        if not torch.cuda.is_available(): # Проверка на доступность CUDA
            print("CUDA не доступна, используется CPU") 
            device = 'cpu'

    if device == 'cuda':
        #Создаем 2 CUDA события для фиксации начала и конца операции
        start_event = torch.cuda.Event(enable_timing=True)
        end_event = torch.cuda.Event(enable_timing=True)

        total_time_ms = 0 #Счетчик времени в милисекундах 
        for run in range(num_runs):
            start_event.record() # Запоминаем момент начала операции
            fn() # выполняем тестируемую функцию
            end_event.record() # запоминаем момент окончания операции
            torch.cuda.synchronize()# ждём завершения всех операций на GPU
            total_time_ms += start_event.elapsed_time(end_event) # добавляем к обзщей сумме

        avg_time = total_time_ms / num_runs #Среденее время
        print(f"GPU Среднее время: {avg_time:.2f} мс")

    else:
        total_time_s = 0 # Счетчик времени в секундах
        for run in range(num_runs):
            start = time.time()  # Запоминаем время до вызова функции
            fn()                 # Вызываем функцию
            end = time.time()    # Запоминаем время после вызова функции
            total_time_s += (end - start) # Считаем длительность одного прогона и добавляем к общей сумме

        avg_time = total_time_s * 1000 / num_runs # Переводим секунды в миллисекунды и считаем среднее
        # print(f"CPU Среднее время: {avg_time:.2f} мс")

    return avg_time
```

### 3.3 Сравнение операций

```python
def run_test(name, op):
    """
    Запускает тестирование одной операции.
    
    Параметры:
        name: название операции (например, 'Сложение')
        op: функция, принимающая a и b, возвращающая результат
    """
    cpu_time = measure_time(lambda: op(tensor_a.cpu(), tensor_b.cpu()), device='cpu') # Измеряем время выполнения операции на CPU

    # Инициализируем время на GPU и ускорение как NaN (Not a Number)
    gpu_time = float('nan')
    speedup = float('nan')

    # Если доступен GPU — измеряем время и считаем ускорение
    if torch.cuda.is_available():
        op_cuda = lambda: op(tensor_a.cuda(), tensor_b.cuda())# Перемещаем тензоры на GPU и вызываем ту же операцию
        
        gpu_time = measure_time(op_cuda, device='cuda')# Измеряем время на GPU
        speedup = cpu_time / gpu_time if gpu_time > 0 else float('inf')# Считаем ускорение (во сколько раз быстрее GPU)
        
    return (name, cpu_time, gpu_time, speedup)

def benchmark_operations(tensor_a, tensor_b):
    """
    Выполняет тестирование основных операций над тензорами.
    
    Параметры:
        tensor_a: первый тензор
        tensor_b: второй тензор (для бинарных операций)

    Возвращает:
        список кортежей (имя_операции, cpu_time, gpu_time, speedup)
    """
    results = []  # Список для хранения результатов
    
    devices = ['cpu']
    if torch.cuda.is_available():# Проверяем, доступен ли CUDA (GPU), и готовим список устройств
        devices.append('cuda')

    mm = run_test("Матричное умножение", lambda a, b: torch.matmul(a, b.transpose(1, 2)))# Матричное умножение
    plus = run_test("Сложение", lambda a, b: a + b)# Поэлементное сложение
    el_mm = run_test("Поэлементное умножение", lambda a, b: a * b)# Поэлементное умножение
    transp = run_test("Транспонирование", lambda a, b: a.transpose(1, 2)) # Транспонирование (меняем оси местами)
    sumi = run_test("Сумма элементов", lambda a, b: a.sum())# Сумма всех элементов тензора

    results= [mm,plus,transp,sumi]# Сохраняем результаты
    
    
    print("\nРезультаты:")
    print("{:<25} | {:>8} | {:>8} | {:>10}".format("Операция", "CPU (мс)", "GPU (мс)", "Ускорение"))
    print("-" * 65)

    for name, cpu_t, gpu_t, speedup in results:
        # Простой вывод: если GPU недоступен или значение не определено - ставим прочерк
        if torch.isnan(torch.tensor(gpu_t)):
            gpu_str = "—"
        else:
            gpu_str = f"{gpu_t:.2f}"

        if torch.isnan(torch.tensor(speedup)):
            speedup_str = "—"
        else:
            speedup_str = f"{speedup:.1f}x"

        # Выводим строку таблицы
        print(f"{name:<25} | {cpu_t:>8.2f} | {gpu_str:>8} | {speedup_str:>10}")
'''
Просто тестируем эффективность каждого способа запуска
'''
# Поочередно меняем тенсоры да более объемные для выявления более заметной разницы между CPU и GPU
tensor_a = tensor3 
tensor_b = tensor3 
benchmark_operations(tensor_a, tensor_b)
```

#### Вывод:
```
GPU Среднее время: 115.68 мс
GPU Среднее время: 107.50 мс
GPU Среднее время: 127.52 мс
GPU Среднее время: 110.12 мс
GPU Среднее время: 114.39 мс

Результаты:
Операция                  | CPU (мс) | GPU (мс) |  Ускорение
-----------------------------------------------------------------
Матричное умножение       |   156.49 |   115.68 |       1.4x
Сложение                  |    14.69 |   107.50 |       0.1x
Транспонирование          |     0.12 |   110.12 |       0.0x
Сумма элементов           |     5.37 |   114.39 |       0.0x
```

## Анализ результатов

### Какие операции получают наибольшее ускорение на GPU?
Наибольшее ускорение наблюдается у матричного умножения — это связано с тем, что GPU оптимизирован для параллельных вычислений.

### Почему некоторые операции могут быть медленнее на GPU?
Простые операции, такие как сложение и транспонирование, требуют мало вычислений, но много подготовки на GPU — основное время уходит на запуск ядра и работу с памятью.

### Как размер матриц влияет на ускорение?
Чем больше данные — тем выше ускорение на GPU. На маленьких данных оверхед на передачу между CPU и GPU может превысить выгоду от параллелизма.

### Что происходит при передаче данных между CPU и GPU?
Копирование данных занимает время. Частые обмены сильно замедляют работу, поэтому лучше минимизировать их количество.

### Комментарии
За оформление заранее простите, наверное на следующей лабораторной меньше комментариев буду писать.
