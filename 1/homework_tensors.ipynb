{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97694078-8296-40ff-926b-c824944cc2d5",
   "metadata": {},
   "source": [
    "## Импорт необходимых библиотек "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1bac7a2-4f88-443b-9583-94747ccc3304",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1a6159-60d3-4d18-a6e6-de87eb2299c7",
   "metadata": {},
   "source": [
    "# Задание 1: Создание и манипуляции с тензорами"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7ef4dc-4727-4477-bcc3-fb421f3b8700",
   "metadata": {},
   "source": [
    "1.1 Создание тензоров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8599547-b081-4943-8bc1-b3cf6619eb21",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вывод 1\n",
      "tensor([[0.2395, 0.7870, 0.7401, 0.7896],\n",
      "        [0.5734, 0.2338, 0.3128, 0.9662],\n",
      "        [0.0896, 0.8370, 0.7336, 0.1947]])\n",
      "Вывод 2\n",
      "tensor([[[0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.]]])\n",
      "Вывод 3\n",
      "tensor([[1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.]])\n",
      "Вывод 4\n",
      "tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11],\n",
      "        [12, 13, 14, 15]])\n"
     ]
    }
   ],
   "source": [
    "#Создается тензор с размером матрицы 3x4 элемента, заполненный чилами от 0 до 1\n",
    "tensor_1 = torch.rand((3,4)) \n",
    "#Создается тензор с 2 слоями матриц размерами 3x4. Все элементы - 0\n",
    "tensor_2 = torch.zeros((2,3,4)) \n",
    "# Тензор размером 5x5 заполненный единицами\n",
    "tensor_3 = torch.ones((5,5))\n",
    "# Сначала создается 1-мерный тензор из чисел 0 до 15 включительно. После этот тензор трансформируем в размерность 4x4 \n",
    "# По факту просто переводим из 1x16 в 4x4 (Заренее извините, если я некоторые вещи называю не своими именами)\n",
    "tensor_4 = torch.arange(0,16).reshape(4,4)\n",
    "\n",
    "#Следующие строки просто для вашего комфортного просмотра результата (Также будет повторятся и в других пунктах)\n",
    "lst_tensor = [tensor_1, tensor_2, tensor_3, tensor_4]\n",
    "for i in range(len(lst_tensor)):\n",
    "    print(f'Вывод {i+1}')\n",
    "    print(lst_tensor[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11136bf0-cd71-4dc7-bb5c-0065b931ee89",
   "metadata": {},
   "source": [
    "1.2 Операции с тензорами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72c66855-8085-4b2e-9ed0-edc0bbd6c181",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тензор А \n",
      " tensor([[0.9666, 0.3297, 0.4372, 0.7688],\n",
      "        [0.3517, 0.1627, 0.2282, 0.8802],\n",
      "        [0.0316, 0.7811, 0.2767, 0.2779]])\n",
      "Тензор B \n",
      " tensor([[0.3806, 0.9090, 0.7039],\n",
      "        [0.3294, 0.5256, 0.4356],\n",
      "        [0.2007, 0.6260, 0.9640],\n",
      "        [0.2518, 0.8301, 0.7948]])\n",
      "Транспонирование тензора A \n",
      " tensor([[0.9666, 0.3517, 0.0316],\n",
      "        [0.3297, 0.1627, 0.7811],\n",
      "        [0.4372, 0.2282, 0.2767],\n",
      "        [0.7688, 0.8802, 0.2779]])\n",
      "Матричное умножение A и B \n",
      " tensor([[0.7578, 1.9638, 1.8565],\n",
      "        [0.4549, 1.2787, 1.2379],\n",
      "        [0.3949, 0.8432, 0.8501]])\n",
      "транспонированный B \n",
      " tensor([[0.3806, 0.3294, 0.2007, 0.2518],\n",
      "        [0.9090, 0.5256, 0.6260, 0.8301],\n",
      "        [0.7039, 0.4356, 0.9640, 0.7948]])\n",
      "Поэлементное умножение A и транспонированного B \n",
      " tensor([[0.3679, 0.1086, 0.0877, 0.1936],\n",
      "        [0.3197, 0.0855, 0.1428, 0.7306],\n",
      "        [0.0223, 0.3402, 0.2667, 0.2209]])\n",
      "Вычислите сумму всех элементов тензора A \n",
      " 5.4922990798950195\n"
     ]
    }
   ],
   "source": [
    "tensor_A = torch.rand((3,4))#Из условия А\n",
    "tensor_B = torch.rand((4,3))#Из условия B\n",
    "print(f'Тензор А \\n {tensor_A}')\n",
    "print(f'Тензор B \\n {tensor_B}')\n",
    "tensor_A_transpose = tensor_A.transpose(0,1) #Транспонирование А\n",
    "print(f'Транспонирование тензора A \\n {tensor_A_transpose}')\n",
    "multi_AB = tensor_A.mm(tensor_B) # Матричное умножение A и B\n",
    "print(f'Матричное умножение A и B \\n {multi_AB}')\n",
    "Btranspose = tensor_B.transpose(0,1) # транспонированный B\n",
    "multi_A_Btranspose = tensor_A * Btranspose # Поэлементное умножение A и транспонированного B\n",
    "print(f'транспонированный B \\n {Btranspose}')\n",
    "print(f'Поэлементное умножение A и транспонированного B \\n {multi_A_Btranspose}')\n",
    "sum_A = torch.sum(tensor_A) #сумма всех элементов тензора A\n",
    "print(f'Вычислите сумму всех элементов тензора A \\n {sum_A}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db05756-9175-4f82-877c-0b7f98b5a77f",
   "metadata": {},
   "source": [
    "1.3 Индексация и срезы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c355430-463a-4a57-bcd5-d93138b9be3c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Изначальный тезор \n",
      "tensor([[[7, 6, 4, 4, 8],\n",
      "         [4, 6, 4, 8, 0],\n",
      "         [3, 5, 2, 7, 4],\n",
      "         [5, 2, 4, 9, 2],\n",
      "         [8, 0, 5, 4, 6]],\n",
      "\n",
      "        [[7, 0, 4, 7, 5],\n",
      "         [4, 5, 0, 2, 1],\n",
      "         [3, 2, 6, 7, 5],\n",
      "         [6, 3, 6, 5, 7],\n",
      "         [1, 4, 2, 8, 4]],\n",
      "\n",
      "        [[8, 8, 0, 2, 1],\n",
      "         [9, 4, 3, 9, 1],\n",
      "         [4, 4, 3, 6, 5],\n",
      "         [8, 0, 7, 3, 3],\n",
      "         [6, 5, 7, 6, 2]],\n",
      "\n",
      "        [[5, 6, 8, 9, 6],\n",
      "         [5, 8, 2, 2, 7],\n",
      "         [3, 3, 5, 2, 9],\n",
      "         [5, 9, 2, 3, 0],\n",
      "         [2, 5, 7, 5, 7]],\n",
      "\n",
      "        [[0, 3, 6, 8, 9],\n",
      "         [7, 6, 5, 6, 1],\n",
      "         [2, 6, 1, 3, 0],\n",
      "         [1, 2, 9, 7, 3],\n",
      "         [9, 0, 8, 4, 9]]])\n",
      "Все первые строки \n",
      "tensor([[7, 6, 4, 4, 8],\n",
      "        [7, 0, 4, 7, 5],\n",
      "        [8, 8, 0, 2, 1],\n",
      "        [5, 6, 8, 9, 6],\n",
      "        [0, 3, 6, 8, 9]])\n",
      "Первая строка 1-го слоя\n",
      "tensor([7, 6, 4, 4, 8])\n",
      "Последний столбец \n",
      "tensor([[8, 0, 4, 2, 6],\n",
      "        [5, 1, 5, 7, 4],\n",
      "        [1, 1, 5, 3, 2],\n",
      "        [6, 7, 9, 0, 7],\n",
      "        [9, 1, 0, 3, 9]])\n",
      "Подматрицу размером 2x2 из центра тензора \n",
      "tensor([[[6, 4, 8],\n",
      "         [5, 2, 7],\n",
      "         [2, 4, 9]],\n",
      "\n",
      "        [[5, 0, 2],\n",
      "         [2, 6, 7],\n",
      "         [3, 6, 5]],\n",
      "\n",
      "        [[4, 3, 9],\n",
      "         [4, 3, 6],\n",
      "         [0, 7, 3]],\n",
      "\n",
      "        [[8, 2, 2],\n",
      "         [3, 5, 2],\n",
      "         [9, 2, 3]],\n",
      "\n",
      "        [[6, 5, 6],\n",
      "         [6, 1, 3],\n",
      "         [2, 9, 7]]])\n",
      "Все элементы с четными индексами \n",
      " tensor([[[7, 4, 8],\n",
      "         [3, 2, 4],\n",
      "         [8, 5, 6]],\n",
      "\n",
      "        [[8, 0, 1],\n",
      "         [4, 3, 5],\n",
      "         [6, 7, 2]],\n",
      "\n",
      "        [[0, 6, 9],\n",
      "         [2, 1, 0],\n",
      "         [9, 8, 9]]])\n"
     ]
    }
   ],
   "source": [
    "tensor555 = torch.randint(0, 10, (5,5,5)) # из условия Задачи\n",
    "print(f'Изначальный тезор \\n{tensor555}')\n",
    "'''\n",
    "Сейчас конкретно есть неясноть, так как в условии написано просто Извлеките первую строку. Непонятно первую строку каждого слоя тензора или первую строку 1-го слоя.\n",
    "Сделал 2 варианта\n",
    "Можно просто запомнить следующее [слой,сторка,столбец] и у всех по стандарту 0, а если заменить на :, то это значит все индексы раздела\n",
    "'''\n",
    "print(f'Все первые строки \\n{tensor555[:,0]}')\n",
    "print(f'Первая строка 1-го слоя\\n{tensor555[0,0]}')\n",
    "# Дальше я буду считать, что нужно выделить объекты для каждого слоя \n",
    "\n",
    "print(f'Последний столбец \\n{tensor555[:,:,-1]}')\n",
    "print(f'Подматрицу размером 2x2 из центра тензора \\n{tensor555[:,1:4,1:4]}') # в строковом разделе я выбираю все индексы от 1 до 4 невлючительно, аналогично со столбцами\n",
    "print(f'Все элементы с четными индексами \\n {tensor555[::2,::2,::2]}') # Выбираю все индексы с шагом 2 (также выбираю слои), таким образом получаю элемент с чет индеком"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2da3882-294f-4889-aa01-c35c892126cb",
   "metadata": {},
   "source": [
    "1.4 Работа с формами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb5e7f38-122f-48ce-b212-04acedc9b984",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тензор размером 2x12 \n",
      "tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11],\n",
      "        [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]])\n",
      "Тензор размером 3x8 \n",
      "tensor([[ 0,  1,  2,  3,  4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11, 12, 13, 14, 15],\n",
      "        [16, 17, 18, 19, 20, 21, 22, 23]])\n",
      "Тензор размером 4x6 \n",
      "tensor([[ 0,  1,  2,  3,  4,  5],\n",
      "        [ 6,  7,  8,  9, 10, 11],\n",
      "        [12, 13, 14, 15, 16, 17],\n",
      "        [18, 19, 20, 21, 22, 23]])\n",
      "Тензор размером 2x3x4 \n",
      "tensor([[[ 0,  1,  2,  3],\n",
      "         [ 4,  5,  6,  7],\n",
      "         [ 8,  9, 10, 11]],\n",
      "\n",
      "        [[12, 13, 14, 15],\n",
      "         [16, 17, 18, 19],\n",
      "         [20, 21, 22, 23]]])\n",
      "Тензор размером 2x2x2x3 \n",
      "tensor([[[[ 0,  1,  2],\n",
      "          [ 3,  4,  5]],\n",
      "\n",
      "         [[ 6,  7,  8],\n",
      "          [ 9, 10, 11]]],\n",
      "\n",
      "\n",
      "        [[[12, 13, 14],\n",
      "          [15, 16, 17]],\n",
      "\n",
      "         [[18, 19, 20],\n",
      "          [21, 22, 23]]]])\n"
     ]
    }
   ],
   "source": [
    "tensor24 = torch.arange(0,24) # Тензор из условия\n",
    "print(f'Тензор размером 2x12 \\n{tensor24.reshape((2,12))}')\n",
    "print(f'Тензор размером 3x8 \\n{tensor24.reshape((3,8))}')\n",
    "print(f'Тензор размером 4x6 \\n{tensor24.reshape((4,6))}')\n",
    "print(f'Тензор размером 2x3x4 \\n{tensor24.reshape((2,3,4))}')\n",
    "print(f'Тензор размером 2x2x2x3 \\n{tensor24.reshape((2,2,2,3))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d45a3b-2ef7-4dfc-9218-908dc9cda824",
   "metadata": {},
   "source": [
    "# Задание 2: Автоматическое дифференцирование"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd3d096-425e-469f-8943-0b5b1a735997",
   "metadata": {},
   "source": [
    "2.1 Простые вычисления с градиентами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0df8b696-4f6a-41d2-a4c5-7f0f835be144",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "производная по x = tensor([36., 58., 84.])\n",
      "производная по y = tensor([ 6., 22., 42.])\n",
      "производная по z = tensor([12., 22., 36.])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nАналитический спопсоб решения (По-идее просто показываем как всё это считалось)\\ndf/dx = 2x + 2yz = [2*0+2*3*6, 2*1+2*4*7, 2*2+2*5*8] = [36, 58, 84]\\nаналогично и с другими\\ndf/dx = 2y + 2xz = [2*3+2*0*6, 2*4+2*1*7, 2*5+2*2*8] = [6, 22, 42]\\ndf/dx = 2z + 2xy = [2*6+2*3*0, 2*7+2*4*1, 2*8+2*5*2] = [12, 22, 36]\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([0.0,1.0,2.0], requires_grad=True)\n",
    "y = torch.tensor([3.0,4.0,5.0], requires_grad=True)\n",
    "z = torch.tensor([6.0,7.0,8.0], requires_grad=True)\n",
    "function = x**2 + y**2 + z**2 + 2*x*y*z # сама функция\n",
    "\n",
    "loss = function.sum()#Представление в виде скалярного числа\n",
    "loss.backward() #Вызываем фунцию backward, чтобы запомнить как получилась function из x,y,z и соответственно для x,y,z высчитывает их производные. Обратное распространение\n",
    "\n",
    "print(f'производная по x = {x.grad}') #Вызываем градиетны для каждой переменной, которые ранее были высчитаны \n",
    "print(f'производная по y = {y.grad}')\n",
    "print(f'производная по z = {z.grad}')\n",
    "'''\n",
    "Аналитический спопсоб решения (По-идее просто показываем как всё это считалось)\n",
    "df/dx = 2x + 2yz = [2*0+2*3*6, 2*1+2*4*7, 2*2+2*5*8] = [36, 58, 84]\n",
    "аналогично и с другими\n",
    "df/dx = 2y + 2xz = [2*3+2*0*6, 2*4+2*1*7, 2*5+2*2*8] = [6, 22, 42]\n",
    "df/dx = 2z + 2xy = [2*6+2*3*0, 2*7+2*4*1, 2*8+2*5*2] = [12, 22, 36]\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9eacf0-e4f2-4d9f-b031-e3812be64c5f",
   "metadata": {},
   "source": [
    "2.2 Градиент функции потерь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d29dc627-2a33-41a9-8e15-7eb05032374a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse = 27.66666603088379\n",
      "градиент w = -22.666667938232422\n",
      "градиент b = -10.0\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1.0, 2.0, 3.0])\n",
    "y_true = torch.tensor([3.0, 5.0, 7.0]) # представление y = 2x + 1\n",
    "# вес и смещение устанавливаю по стандарту как 0\n",
    "w = torch.tensor(0.0, requires_grad=True)\n",
    "b = torch.tensor(0.0, requires_grad=True)\n",
    "y_pred = w*x+b \n",
    "mse = ((y_pred-y_true)**2).mean() # Судя по документации, в pytorch функция mean уже учитывает сумму и n\n",
    "mse.backward() #также делаем обратное распространение \n",
    "print(f'mse = {mse.item()}')\n",
    "print(f'градиент w = {w.grad.item()}')\n",
    "print(f'градиент b = {b.grad.item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479b7ddc-60fc-4531-9a48-b1416e6565a3",
   "metadata": {
    "tags": []
   },
   "source": [
    "2.3 Цепное правило"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b0b3860a-d84c-4eba-b7ba-8f523ca91667",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df/dx = 1.1346487998962402\n",
      "Проверка с помощью torch.autograd.grad = 1.1346487998962402\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(2.0, requires_grad=True)\n",
    "function = torch.sin(x**2 + 1)\n",
    "\n",
    "# Считаем градиент через backward()\n",
    "function.backward(retain_graph=True)  # сохраняем граф, без этого иначе почему то ловит ошибку\n",
    "print(f'df/dx = {x.grad}')\n",
    "\n",
    "# Проверяем через autograd.grad\n",
    "df_dx = torch.autograd.grad(function, x)[0]\n",
    "print(f'Проверка с помощью torch.autograd.grad = {df_dx}')\n",
    "#результаты совпали"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9acb652a-2e2e-40f5-932d-e4aeaaaa456f",
   "metadata": {},
   "source": [
    "# Задание 3: Сравнение производительности CPU vs CUDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f0a83c-a70d-4620-8b87-9d23d30bdb04",
   "metadata": {},
   "source": [
    "3.1 Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7f5131c7-485c-4b95-84b4-ea16e35265f8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor 64x1024x1024: torch.Size([64, 1024, 1024])\n",
      "Tensor 128x512x512: torch.Size([128, 512, 512])\n",
      "Tensor 256x256x256: torch.Size([256, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "tensor1 = torch.rand((64,1024,1024))\n",
    "tensor2 = torch.rand((128,512,512))\n",
    "tensor3 = torch.rand((256,256,256)) # Думаю из предыдущих заданий понятно все, что тут делается\n",
    "print(f\"Tensor 64x1024x1024: {tensor1.shape}\")\n",
    "print(f\"Tensor 128x512x512: {tensor2.shape}\")\n",
    "print(f\"Tensor 256x256x256: {tensor3.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c89a5a-aa17-4a74-a951-1ad949148119",
   "metadata": {},
   "source": [
    "3.2 Функция измерения времени"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a2f31a9e-2ab9-441a-900a-055b41c97edf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def measure_time(fn, device='cpu', num_runs=10):\n",
    "    '''\n",
    "    Измеряет время выполнения функции fn.\n",
    "    Параметры:\n",
    "        fn: вызываемая функция без аргументов\n",
    "        device: 'cpu' или 'cuda'\n",
    "        num_runs: количество прогонов для усреднения\n",
    "    Возвращает среднее время выполнения в миллисекундах\n",
    "    '''\n",
    "    if device == 'cuda': \n",
    "        if not torch.cuda.is_available(): # Проверка на доступность CUDA\n",
    "            print(\"CUDA не доступна, используется CPU\") \n",
    "            device = 'cpu'\n",
    "\n",
    "    if device == 'cuda':\n",
    "        #Создаем 2 CUDA события для фиксации начала и конца операции\n",
    "        start_event = torch.cuda.Event(enable_timing=True)\n",
    "        end_event = torch.cuda.Event(enable_timing=True)\n",
    "\n",
    "        total_time_ms = 0 #Счетчик времени в милисекундах \n",
    "        for run in range(num_runs):\n",
    "            start_event.record() # Запоминаем момент начала операции\n",
    "            fn() # выполняем тестируемую функцию\n",
    "            end_event.record() # запоминаем момент окончания операции\n",
    "            torch.cuda.synchronize()# ждём завершения всех операций на GPU\n",
    "            total_time_ms += start_event.elapsed_time(end_event) # добавляем к обзщей сумме\n",
    "\n",
    "        avg_time = total_time_ms / num_runs #Среденее время\n",
    "        print(f\"GPU Среднее время: {avg_time:.2f} мс\")\n",
    "\n",
    "    else:\n",
    "        total_time_s = 0 # Счетчик времени в секундах\n",
    "        for run in range(num_runs):\n",
    "            start = time.time()  # Запоминаем время до вызова функции\n",
    "            fn()                 # Вызываем функцию\n",
    "            end = time.time()    # Запоминаем время после вызова функции\n",
    "            total_time_s += (end - start) # Считаем длительность одного прогона и добавляем к общей сумме\n",
    "\n",
    "        avg_time = total_time_s * 1000 / num_runs # Переводим секунды в миллисекунды и считаем среднее\n",
    "        # print(f\"CPU Среднее время: {avg_time:.2f} мс\")\n",
    "\n",
    "    return avg_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03f10fc-26ff-4ccc-bccf-1b1f6f1f36d2",
   "metadata": {},
   "source": [
    "3.3 Сравнение операций"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f010b90f-1859-44e6-8cc6-d6ad632ad859",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_test(name, op):\n",
    "    \"\"\"\n",
    "    Запускает тестирование одной операции.\n",
    "    \n",
    "    Параметры:\n",
    "        name: название операции (например, 'Сложение')\n",
    "        op: функция, принимающая a и b, возвращающая результат\n",
    "    \"\"\"\n",
    "    cpu_time = measure_time(lambda: op(tensor_a.cpu(), tensor_b.cpu()), device='cpu') # Измеряем время выполнения операции на CPU\n",
    "\n",
    "    # Инициализируем время на GPU и ускорение как NaN (Not a Number)\n",
    "    gpu_time = float('nan')\n",
    "    speedup = float('nan')\n",
    "\n",
    "    # Если доступен GPU — измеряем время и считаем ускорение\n",
    "    if torch.cuda.is_available():\n",
    "        op_cuda = lambda: op(tensor_a.cuda(), tensor_b.cuda())# Перемещаем тензоры на GPU и вызываем ту же операцию\n",
    "        \n",
    "        gpu_time = measure_time(op_cuda, device='cuda')# Измеряем время на GPU\n",
    "        speedup = cpu_time / gpu_time if gpu_time > 0 else float('inf')# Считаем ускорение (во сколько раз быстрее GPU)\n",
    "        \n",
    "    return (name, cpu_time, gpu_time, speedup)\n",
    "\n",
    "def benchmark_operations(tensor_a, tensor_b):\n",
    "    \"\"\"\n",
    "    Выполняет тестирование основных операций над тензорами.\n",
    "    \n",
    "    Параметры:\n",
    "        tensor_a: первый тензор\n",
    "        tensor_b: второй тензор (для бинарных операций)\n",
    "\n",
    "    Возвращает:\n",
    "        список кортежей (имя_операции, cpu_time, gpu_time, speedup)\n",
    "    \"\"\"\n",
    "    results = []  # Список для хранения результатов\n",
    "    \n",
    "    devices = ['cpu']\n",
    "    if torch.cuda.is_available():# Проверяем, доступен ли CUDA (GPU), и готовим список устройств\n",
    "        devices.append('cuda')\n",
    "\n",
    "    mm = run_test(\"Матричное умножение\", lambda a, b: torch.matmul(a, b.transpose(1, 2)))# Матричное умножение\n",
    "    plus = run_test(\"Сложение\", lambda a, b: a + b)# Поэлементное сложение\n",
    "    el_mm = run_test(\"Поэлементное умножение\", lambda a, b: a * b)# Поэлементное умножение\n",
    "    transp = run_test(\"Транспонирование\", lambda a, b: a.transpose(1, 2)) # Транспонирование (меняем оси местами)\n",
    "    sumi = run_test(\"Сумма элементов\", lambda a, b: a.sum())# Сумма всех элементов тензора\n",
    "\n",
    "    results= [mm,plus,transp,sumi]# Сохраняем результаты\n",
    "    \n",
    "    \n",
    "    print(\"\\nРезультаты:\")\n",
    "    print(\"{:<25} | {:>8} | {:>8} | {:>10}\".format(\"Операция\", \"CPU (мс)\", \"GPU (мс)\", \"Ускорение\"))\n",
    "    print(\"-\" * 65)\n",
    "\n",
    "    for name, cpu_t, gpu_t, speedup in results:\n",
    "        # Простой вывод: если GPU недоступен или значение не определено - ставим прочерк\n",
    "        if torch.isnan(torch.tensor(gpu_t)):\n",
    "            gpu_str = \"—\"\n",
    "        else:\n",
    "            gpu_str = f\"{gpu_t:.2f}\"\n",
    "\n",
    "        if torch.isnan(torch.tensor(speedup)):\n",
    "            speedup_str = \"—\"\n",
    "        else:\n",
    "            speedup_str = f\"{speedup:.1f}x\"\n",
    "\n",
    "        # Выводим строку таблицы\n",
    "        print(f\"{name:<25} | {cpu_t:>8.2f} | {gpu_str:>8} | {speedup_str:>10}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8652946a-7064-4bd7-b94b-2698668f9ba9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Среднее время: 115.68 мс\n",
      "GPU Среднее время: 107.50 мс\n",
      "GPU Среднее время: 127.52 мс\n",
      "GPU Среднее время: 110.12 мс\n",
      "GPU Среднее время: 114.39 мс\n",
      "\n",
      "Результаты:\n",
      "Операция                  | CPU (мс) | GPU (мс) |  Ускорение\n",
      "-----------------------------------------------------------------\n",
      "Матричное умножение       |   156.49 |   115.68 |       1.4x\n",
      "Сложение                  |    14.69 |   107.50 |       0.1x\n",
      "Транспонирование          |     0.12 |   110.12 |       0.0x\n",
      "Сумма элементов           |     5.37 |   114.39 |       0.0x\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Просто тестируем эффективность каждого способа запуска\n",
    "'''\n",
    "# Поочередно меняем тенсоры да более объемные для выявления более заметной разницы между CPU и GPU\n",
    "tensor_a = tensor3 \n",
    "tensor_b = tensor3 \n",
    "benchmark_operations(tensor_a, tensor_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95191b13-6938-43e3-824f-8f389783b40c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Какие операции получают наибольшее ускорение на GPU?\n",
    "Наибольшее ускорение на GPU наблюдается у матричного умножения. \n",
    "Это связано с тем, что GPU отлично справляется с параллельными вычислениями, а матричное умножение — как раз такая задача. Остальные операции показывают низкое или отрицательное ускорение.\n",
    "# Почему некоторые операции могут быть медленнее на GPU?\n",
    "Простые операции вроде сложения или транспонирования требуют мало вычислений, но много подготовки на GPU. Основное время тратится на запуск ядра и работу с памятью, поэтому такие задачи эффективнее выполнять на CPU.\n",
    "# Как размер матриц влияет на ускорение?\n",
    "Чем больше данные, тем выше потенциальное ускорение на GPU. Однако при малых размерах данных оверхед на передачу в GPU может превысить выгоду от параллелизма, и тогда GPU становится неэффективным.\n",
    "# Что происходит при передаче данных между CPU и GPU?\n",
    "Передача данных между CPU и GPU занимает время, особенно при частых обменах. Это сильно влияет на производительность, особенно если каждая операция требует копирования туда-обратно. Лучше минимизировать такие переключения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2e3112-e2e5-4d52-9b9c-ca7933779f99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
