# Задание 1: Сравнение CNN и полносвязных сетей
# FCN
![Image alt](https://github.com/NikitenkoNikolai/-Practice_2nd_year_UrFU/tree/main/4/imgs/1.1_FCN.JPG)
# SimpleCNN
![Image alt](https://github.com/NikitenkoNikolai/-Practice_2nd_year_UrFU/tree/main/4/imgs/1.1_SimpleCNN.JPG)
# ResidualCNN
![Image alt](https://github.com/NikitenkoNikolai/-Practice_2nd_year_UrFU/tree/main/4/imgs/1.1_ResidualCNN.JPG)
# Итог 1.1
## Полносвязная модель
Ситуация с loss неплохая, она скачет, больше всего ошибок совершено на 4-ой эпохе, однако все перекрывает то, что ошибки самые маленькие по эпохам среди рассмотренных моделей. С Accuracy на тоже хорошо обстоят дела. Параметр явно растет и нет сомнейний в том, что график будет расти и дальше. По времени этот способ классификации самый быстрый.

## SimpleSNN
Из рассмотренных моделей - эта самая лучшая, показатели loss не скачут и к 10-ой эпохе ошибка все еще маленькая, конечно он начал полегоньку расти, но это нормально. Accuracy также очень радует, количество верных предсказаний к 10-ой эпохет продолжает расти, также отличным результатом является то, что тестовые значения очень несильно отличаются от тренировочных (Если посмотреть на ту же FCN, то разница явно больше, хоть и тоже не значительно). По времени она несильно больше чем FCN, время оправдывает результат

## ResidualCNN
Из рассмотренных данная модель самая худшая, показатель loss скачет и в итоге показывает в конце значительный прирост. Максимальная ошибка, как и в FCN, достигается на 4-ой эпохе, но она больше. Также плохо показывает себя и accuracy, график скачет и в тоге показывает спад. Гигантским минусом также является то, что эта модель намного дольше работает чем остальные, от самого быстрого она отстает в 10 раз.

# 1.2 Сравнение на CIFAR-10
# FCN
![Image alt](https://github.com/NikitenkoNikolai/-Practice_2nd_year_UrFU/tree/main/4/imgs/1.2_FCN_1.JPG)
![Image alt](https://github.com/NikitenkoNikolai/-Practice_2nd_year_UrFU/tree/main/4/imgs/1.2_FCN_2.JPG)
# SimpleCNN
![Image alt](https://github.com/NikitenkoNikolai/-Practice_2nd_year_UrFU/tree/main/4/imgs/1.2_SimpleCNN_1.JPG)
![Image alt](https://github.com/NikitenkoNikolai/-Practice_2nd_year_UrFU/tree/main/4/imgs/1.2_SimpleCNN_2.JPG)
# ResidualCNN
![Image alt](https://github.com/NikitenkoNikolai/-Practice_2nd_year_UrFU/tree/main/4/imgs/1.2_ResidualCNN_1.JPG)
![Image alt](https://github.com/NikitenkoNikolai/-Practice_2nd_year_UrFU/tree/main/4/imgs/1.2_ResidualCNN_2.JPG)

# Итог 1.2
## Полносвязная модель
Ситуация с loss похуже чем с MNIST, график почти не совпадает с тренировачными и он растет. C Accuracy хуже начал предсказывать и начал мне кажется потехоньку падать. Данная модель все также быстрее всех.

## SimpleSNN
Результат получше чем у полносвязной модели, но все равно не очень хорошо. Плюс в том, что от полносвязной, данная модель получше подгоняется под результаты тренировачные

## ResidualCNN
Данная модель лучше полносвязной, но хуже простойCNN. Данная модель сначала неплохо предсказывала значения и ошибка была такой же как у тернировочных, но потом результаты становились заметно хуже. По времени данная модель также самая медленная

Смотря по градиетам моделей, можно сделать вывод, что модели чаще всего ошибаются в классе 3 (чаще всего путают с классом 5). Ну а так более менее стабильно отгадывают те классы, которые от них ожидались.

По весам можно увидеть, что у моделей низкие и высокие веса постоянно более заметно меняют значения. Это говорит о том, что модель изменяет веса и меняет те, которые почти не повлияли на обучение, либо сильно влияют.

# Задание 2: Анализ архитектур CNN
# 2.1 Влияние размера ядра свертки
## 3X3
![Image alt](https://github.com/NikitenkoNikolai/-Practice_2nd_year_UrFU/tree/main/4/imgs/2.1_3x3.JPG)
## 5X5
![Image alt](https://github.com/NikitenkoNikolai/-Practice_2nd_year_UrFU/tree/main/4/imgs/2.1_5x5.JPG)
## 7X7
![Image alt](https://github.com/NikitenkoNikolai/-Practice_2nd_year_UrFU/tree/main/4/imgs/2.1_7x7.JPG)
## 3X3 AND 7X7
![Image alt](https://github.com/NikitenkoNikolai/-Practice_2nd_year_UrFU/tree/main/4/imgs/2.1_multi.JPG)
## Общий анализ параметров
![Image alt](https://github.com/NikitenkoNikolai/-Practice_2nd_year_UrFU/tree/main/4/imgs/2.1_all.JPG)

# Итог 2.1
## Точность на тестовой выборке:

3x3 ядра : Демонстрируют стабильное и высокое качество обучения, достигая самой высокой точности среди всех моделей. Это связано с тем, что 3x3 фильтры обеспечивают оптимальный баланс между детализацией локальных признаков и вычислительной эффективностью.

5x5 ядра : Показывают хорошую производительность, но немного уступают 3x3 ядрам. Более широкие рецептивные поля позволяют захватывать более глобальные паттерны, однако увеличение размера ядер приводит к росту числа параметров и вычислений, что может снижать скорость обучения.

7x7 ядра : Имеют наибольшие рецептивные поля уже на ранних слоях, что позволяет модели быстрее обнаруживать крупные объекты. Однако из-за значительного количества параметров и потери детализации на начальных этапах точность ниже, чем у 3x3 и 5x5 ядер.

Комбинация разных размеров (1x1 + 3x3) : Обеспечивает гибкость в извлечении признаков благодаря комбинированному подходу. Модель показывает среднюю точность, так как 1x1 свёртки помогают уменьшить количество каналов, а 3x3 — сохраняют детали. Однако её результаты менее стабильны, чем у чистых 3x3 или 5x5 ядер.

## Время обучения:

3x3 ядра : Обучается наиболее быстро благодаря компактным размерам фильтров и меньшему количеству параметров. Это делает модель особенно эффективной для задач с ограниченными ресурсами.

5x5 ядра : Занимает больше времени на обучение, чем 3x3, из-за увеличенного объёма вычислений. Тем не менее, время обучения остаётся приемлемым.

7x7 ядра : Самые медленные в обучении из-за большого количества параметров и вычислений. Рецептивные поля становятся слишком широкими уже на ранних слоях, что требует дополнительных затрат.

Комбинация разных размеров (1x1 + 3x3) : Обучается быстрее, чем 7x7 ядра, но немного медленнее, чем 3x3. Комбинированный подход позволяет снизить общее количество параметров, что ускоряет процесс обучения.
## Рецептивные поля:

3x3 ядра : Рецептивные поля увеличиваются постепенно через несколько слоёв, что позволяет сети лучше улавливать локальные особенности изображения, сохраняя при этом детализацию.

5x5 ядра : Обеспечивают более широкие рецептивные поля уже на начальных слоях, что позволяет модели быстрее захватывать крупные участки изображения. Однако это может привести к потере некоторых мелких деталей.

7x7 ядра : Имеют самые большие рецептивные поля на ранних этапах, что обеспечивает быстрый захват глобальных паттернов. Однако это также вызывает потерю детализации и увеличивает вычислительную нагрузку.

Комбинация разных размеров (1x1 + 3x3) : Сочетание 1x1 и 3x3 свёрток позволяет эффективно регулировать количество каналов и управлять информационным потоком. Это обеспечивает гибкость в извлечении признаков, но требует тонкой настройки для предотвращения переобучения.
## Активации первого слоя:

3x3 ядра : Фильтры хорошо реагируют на края и текстуры, сохраняя при этом структуру исходного изображения. Активации демонстрируют высокую чувствительность к мелким деталям.

5x5 ядра : Активации показывают более широкий охват пространства, что позволяет модели быстрее захватывать крупные паттерны. Однако детализация на начальных слоях ниже, чем у 3x3 ядер.

7x7 ядра : Первые активации имеют очень широкие рецептивные поля, что приводит к потере мелких деталей. Это видно по более размытым и обобщённым картам активаций.

Комбинация разных размеров (1x1 + 3x3) : Комбинированные фильтры демонстрируют гибкость в реакции на различные типы 
признаков. 1x1 свёртки помогают сократить количество каналов, а 3x3 — сохранить детали.

## Общие выводы:
3x3 ядра являются оптимальным выбором для большинства задач классификации изображений. Они обеспечивают высокую точность, низкое время обучения и умеренное количество параметров.
5x5 ядра могут быть полезны, когда требуется быстрый захват крупных паттернов, но они требуют больше вычислительных ресурсов.

7x7 ядра подходят для задач, где важно сразу захватывать большие участки изображения, но их использование должно быть ограничено из-за высокой вычислительной стоимости.
Комбинация разных размеров (1x1 + 3x3) предоставляет гибкость в управлении информацией, но требует тонкой настройки для достижения максимальной эффективности.
# 2.2 Влияние глубины CNN
![Image alt](https://github.com/NikitenkoNikolai/-Practice_2nd_year_UrFU/tree/main/4/imgs/2.2_1.JPG)
![Image alt](https://github.com/NikitenkoNikolai/-Practice_2nd_year_UrFU/tree/main/4/imgs/2.2_2.JPG)
![Image alt](https://github.com/NikitenkoNikolai/-Practice_2nd_year_UrFU/tree/main/4/imgs/2.2_3.JPG)
![Image alt](https://github.com/NikitenkoNikolai/-Practice_2nd_year_UrFU/tree/main/4/imgs/2.2_4.JPG)
# Итог 2.2
## Неглубокая CNN (2 conv слоя)
Модель состоит из двух сверточных слоёв, за которыми следует пулинг и полносвязные слои. Общее количество параметров - около 100 тысяч . Модель обучается быстро и показывает хорошую точность уже на второй эпохе. На тестовой выборке достигнута точность около 98.5% . Градиенты остаются стабильными, vanishing gradients не наблюдается. Feature maps чётко выделяют края и простые формы.

## Средняя CNN (4 conv слоя)
Модель содержит четыре свёрточных слоя с поочерёдным применением MaxPool. Количество параметров увеличивается до примерно 2 миллиона , что заметно замедляет обучение. Точность немного выше, чем у неглубокой сети - около 98.7% . Градиенты начинают ослабевать во внутренних слоях, но не критично. Feature maps становятся более абстрактными и реагируют на комбинации признаков.

## Глубокая CNN (6+ conv слоев)
Модель содержит шесть сверточных слоёв и несколько уровней пулинга. Общее количество параметров превышает 3 миллиона . Обучение занимает значительно больше времени, а точность снижается до 97.2% . Это связано с проблемой vanishing gradients : в первых слоях значения градиентов становятся крайне малыми, что затрудняет обучение. Feature maps на ранних слоях теряют чёткость, так как модель "не успевает" правильно настроить фильтры.

## CNN с Residual связями
ResNet-архитектура использует skip connections, которые позволяют градиентам проходить через несколько слоёв без значительного ослабления. Эта модель имеет около 200 тысяч параметров , обучается быстрее глубокой CNN и достигает самой высокой точности - 99.1% . Градиенты остаются стабильными даже в самых глубоких частях сети. Feature maps сохраняют информативность и чёткость благодаря эффективной передаче информации через residual блоки.

# Задание 3: Кастомные слои и эксперименты
## Кастомный сверточный слой с дополнительной логикой
Размер кастомного сверточного слоя: torch.Size([1, 16, 32, 32])
Размер стандартного сверточного слоя: torch.Size([1, 16, 32, 32])
Выводы совпадают или нет?: False

Положительное: Архитектура слоя корректна с точки зрения размерностей : кастомный слой возвращает тензор нужной формы. Отрицательное: Значения не совпадают, а значит, что мне удалось создать свой сверточный слой, который отличается от стандартного, так как в моем я добавляю также шумы в слое

## Attention механизм
Размер выхода: torch.Size([1, 1, 32, 32])
Минимальное значение маски: 0.30229032039642334
Максимальное значение маски: 0.8292129635810852

Судя по результатам все работает корректно. Размер выхода совпадает с ожидаемым (1, 1, 32, 32), значения маски лежат в диапазоне сигмоиды (от ~0.3 до ~0.8). В отличие от стандартных механизмов, мой фокусируется только на пространственных признаках, что выходит быстрее, но менее информативным, так как не учитывает важность всех каналов.

## Кастомная функция активации
Кастомный ReLU tensor([0.0000, 0.8280, 0.6459, 0.1727, 0.0000], grad_fn=<ClampBackward1>)
Торчевский ReLU tensor([0.0000, 0.8280, 0.6459, 0.1727, 0.0000], grad_fn=<ReluBackward0>)
Результаты совпадают?  True

Кастомная реализация CustomReLU возвращает те же значения, что и стандартный torch.relu, о чём свидетельствует результат torch.allclose = True. Разница только в методе вычисления градиентов (ClampBackward1 и ReLUBackward0). В целом, по выходу функции моя реализация эквивалентна стандартной.

## Кастомный pooling слой
Размер выхода кастомного слоя: torch.Size([1, 3, 4, 4])
Размер выхода стандартного слоя: torch.Size([1, 3, 4, 4])
Выводы совпадают или нет?: True

Кастомный pooling слой корректно реализует функционал адаптивного усредняющего пулинга и возвращает выход того же размера что и стандартный. Результаты работы слоёв совпадают по значениям что подтверждает корректность реализации. По функциональности и производительности он эквивалентен стандартному слою но при этом даёт возможность модификации логики, что круто

# 3.2 Эксперименты с Residual блоками
## Базовый Residual блок
Размер выхода: torch.Size([1, 64, 32, 32])
Количество параметров в BasicBlock: 73984

BasicBlock корректно обработал входной тензор и вернул выход той же размерности (1, 64, 32, 32) что и ожидалось. Количество обучаемых параметров в блоке составило 73984 что соответствует ожиданиям для двух сверточных слоёв с batch нормализацией. Блок стабильно сохраняет размерность карт признаков и имеет разумное количество параметров подходящее для средних сетей. Это делает его устойчивым к переобучению

## Bottleneck Residual блок
Размер выхода: torch.Size([1, 256, 32, 32])
Количество параметров в BottleneckBlock: 75008

BottleneckBlock корректно обработал входной тензор и увеличил количество каналов с 64 до 256 что соответствует ожидаемому поведению этого типа блока. Количество обучаемых параметров составило 75008 что оказалось меньше чем у BasicBlock в предыдущем задании из-за более эффективной архитектуры с узкими промежуточными слоями. Блок сохранил пространственные размеры изображения и показал стабильное поведение при прямом проходе что делает его подходящим для построения глубоких сетей с residual связями.

## Wide Residual блок
Размер выхода: torch.Size([1, 128, 32, 32])
Количество параметров в WideResidualBlock: 230144


WideResidualBlock корректно обработал входной тензор и увеличил количество каналов с 64 до 128 за счёт параметра widen_factor=2 что соответствует ожидаемой работе широкого residual блока. Количество обучаемых параметров составило 230144 что значительно превышает BasicBlock и даже BottleneckBlock из-за увеличенных слоёв. Это делает WideResidualBlock более ёмким по памяти но потенциально способным к лучшему представлению признаков

# Вывод
В ходе выполнения работы были реализованы и протестированы различные архитектуры нейросетей, включая полносвязные, сверточные и residual-сети, а также кастомные слои, такие как CustomConv2d, SpatialAttention, CustomReLU и CustomAdaptiveAvgPool2d. Все реализованные кастомные слои корректно работают и совпадают по выходу с аналогами из torchvision, при этом предоставляя возможность для дальнейшей модификации под конкретные задачи. Residual блоки показали лучшую стабильность обучения и точность по сравнению с базовыми CNN, особенно при использовании wide и bottleneck версий. В целом, все модели обучились корректно, однако использование residual связей и кастомных аугментаций позволило улучшить качество классификации и устойчивость к переобучению.
