# Задание 1: Сравнение CNN и полносвязных сетей
# FCN
![Image alt](https://github.com/NikitenkoNikolai/-Practice_2nd_year_UrFU/tree/main/4/imgs/1.1_FCN.JPG)
# SimpleCNN
![Image alt](https://github.com/NikitenkoNikolai/-Practice_2nd_year_UrFU/tree/main/4/imgs/1.1_SimpleCNN.JPG)
# ResidualCNN
![Image alt](https://github.com/NikitenkoNikolai/-Practice_2nd_year_UrFU/tree/main/4/imgs/1.1_ResidualCNN.JPG)
# Итог 1.1
## Полносвязная модель
Ситуация с loss неплохая, она скачет, больше всего ошибок совершено на 4-ой эпохе, однако все перекрывает то, что ошибки самые маленькие по эпохам среди рассмотренных моделей. С Accuracy на тоже хорошо обстоят дела. Параметр явно растет и нет сомнейний в том, что график будет расти и дальше. По времени этот способ классификации самый быстрый.

## SimpleSNN
Из рассмотренных моделей - эта самая лучшая, показатели loss не скачут и к 10-ой эпохе ошибка все еще маленькая, конечно он начал полегоньку расти, но это нормально. Accuracy также очень радует, количество верных предсказаний к 10-ой эпохет продолжает расти, также отличным результатом является то, что тестовые значения очень несильно отличаются от тренировочных (Если посмотреть на ту же FCN, то разница явно больше, хоть и тоже не значительно). По времени она несильно больше чем FCN, время оправдывает результат

## ResidualCNN
Из рассмотренных данная модель самая худшая, показатель loss скачет и в итоге показывает в конце значительный прирост. Максимальная ошибка, как и в FCN, достигается на 4-ой эпохе, но она больше. Также плохо показывает себя и accuracy, график скачет и в тоге показывает спад. Гигантским минусом также является то, что эта модель намного дольше работает чем остальные, от самого быстрого она отстает в 10 раз.

# 1.2 Сравнение на CIFAR-10
# FCN
![Image alt](https://github.com/NikitenkoNikolai/-Practice_2nd_year_UrFU/tree/main/4/imgs/1.2_FCN_1.JPG)
![Image alt](https://github.com/NikitenkoNikolai/-Practice_2nd_year_UrFU/tree/main/4/imgs/1.2_FCN_2.JPG)
# SimpleCNN
![Image alt](https://github.com/NikitenkoNikolai/-Practice_2nd_year_UrFU/tree/main/4/imgs/1.2_SimpleCNN_1.JPG)
![Image alt](https://github.com/NikitenkoNikolai/-Practice_2nd_year_UrFU/tree/main/4/imgs/1.2_SimpleCNN_2.JPG)
# ResidualCNN
![Image alt](https://github.com/NikitenkoNikolai/-Practice_2nd_year_UrFU/tree/main/4/imgs/1.2_ResidualCNN_1.JPG)
![Image alt](https://github.com/NikitenkoNikolai/-Practice_2nd_year_UrFU/tree/main/4/imgs/1.2_ResidualCNN_2.JPG)

# Итог 1.2
## Полносвязная модель
Ситуация с loss похуже чем с MNIST, график почти не совпадает с тренировачными и он растет. C Accuracy хуже начал предсказывать и начал мне кажется потехоньку падать. Данная модель все также быстрее всех.

## SimpleSNN
Результат получше чем у полносвязной модели, но все равно не очень хорошо. Плюс в том, что от полносвязной, данная модель получше подгоняется под результаты тренировачные

## ResidualCNN
Данная модель лучше полносвязной, но хуже простойCNN. Данная модель сначала неплохо предсказывала значения и ошибка была такой же как у тернировочных, но потом результаты становились заметно хуже. По времени данная модель также самая медленная

Смотря по градиетам моделей, можно сделать вывод, что модели чаще всего ошибаются в классе 3 (чаще всего путают с классом 5). Ну а так более менее стабильно отгадывают те классы, которые от них ожидались.

По весам можно увидеть, что у моделей низкие и высокие веса постоянно более заметно меняют значения. Это говорит о том, что модель изменяет веса и меняет те, которые почти не повлияли на обучение, либо сильно влияют.
