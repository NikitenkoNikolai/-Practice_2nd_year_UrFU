# Задание 1: Сравнение CNN и полносвязных сетей
# FCN
![Image alt](https://github.com/NikitenkoNikolai/-Practice_2nd_year_UrFU/tree/main/4/imgs/1.1_FCN.JPG)
# SimpleCNN
![Image alt](https://github.com/NikitenkoNikolai/-Practice_2nd_year_UrFU/tree/main/4/imgs/1.1_SimpleCNN.JPG)
# ResidualCNN
![Image alt](https://github.com/NikitenkoNikolai/-Practice_2nd_year_UrFU/tree/main/4/imgs/1.1_ResidualCNN.JPG)
# Итог 1.1
## Полносвязная модель
Ситуация с loss неплохая, она скачет, больше всего ошибок совершено на 4-ой эпохе, однако все перекрывает то, что ошибки самые маленькие по эпохам среди рассмотренных моделей. С Accuracy на тоже хорошо обстоят дела. Параметр явно растет и нет сомнейний в том, что график будет расти и дальше. По времени этот способ классификации самый быстрый.

## SimpleSNN
Из рассмотренных моделей - эта самая лучшая, показатели loss не скачут и к 10-ой эпохе ошибка все еще маленькая, конечно он начал полегоньку расти, но это нормально. Accuracy также очень радует, количество верных предсказаний к 10-ой эпохет продолжает расти, также отличным результатом является то, что тестовые значения очень несильно отличаются от тренировочных (Если посмотреть на ту же FCN, то разница явно больше, хоть и тоже не значительно). По времени она несильно больше чем FCN, время оправдывает результат

## ResidualCNN
Из рассмотренных данная модель самая худшая, показатель loss скачет и в итоге показывает в конце значительный прирост. Максимальная ошибка, как и в FCN, достигается на 4-ой эпохе, но она больше. Также плохо показывает себя и accuracy, график скачет и в тоге показывает спад. Гигантским минусом также является то, что эта модель намного дольше работает чем остальные, от самого быстрого она отстает в 10 раз.

# 1.2 Сравнение на CIFAR-10
# FCN
![Image alt](https://github.com/NikitenkoNikolai/-Practice_2nd_year_UrFU/tree/main/4/imgs/1.2_FCN_1.JPG)
![Image alt](https://github.com/NikitenkoNikolai/-Practice_2nd_year_UrFU/tree/main/4/imgs/1.2_FCN_2.JPG)
# SimpleCNN
![Image alt](https://github.com/NikitenkoNikolai/-Practice_2nd_year_UrFU/tree/main/4/imgs/1.2_SimpleCNN_1.JPG)
![Image alt](https://github.com/NikitenkoNikolai/-Practice_2nd_year_UrFU/tree/main/4/imgs/1.2_SimpleCNN_2.JPG)
# ResidualCNN
![Image alt](https://github.com/NikitenkoNikolai/-Practice_2nd_year_UrFU/tree/main/4/imgs/1.2_ResidualCNN_1.JPG)
![Image alt](https://github.com/NikitenkoNikolai/-Practice_2nd_year_UrFU/tree/main/4/imgs/1.2_ResidualCNN_2.JPG)

# Итог 1.2
## Полносвязная модель
Ситуация с loss похуже чем с MNIST, график почти не совпадает с тренировачными и он растет. C Accuracy хуже начал предсказывать и начал мне кажется потехоньку падать. Данная модель все также быстрее всех.

## SimpleSNN
Результат получше чем у полносвязной модели, но все равно не очень хорошо. Плюс в том, что от полносвязной, данная модель получше подгоняется под результаты тренировачные

## ResidualCNN
Данная модель лучше полносвязной, но хуже простойCNN. Данная модель сначала неплохо предсказывала значения и ошибка была такой же как у тернировочных, но потом результаты становились заметно хуже. По времени данная модель также самая медленная

Смотря по градиетам моделей, можно сделать вывод, что модели чаще всего ошибаются в классе 3 (чаще всего путают с классом 5). Ну а так более менее стабильно отгадывают те классы, которые от них ожидались.

По весам можно увидеть, что у моделей низкие и высокие веса постоянно более заметно меняют значения. Это говорит о том, что модель изменяет веса и меняет те, которые почти не повлияли на обучение, либо сильно влияют.

# Задание 2: Анализ архитектур CNN
# 2.1 Влияние размера ядра свертки
## 3X3
![Image alt](https://github.com/NikitenkoNikolai/-Practice_2nd_year_UrFU/tree/main/4/imgs/2.1_3x3.JPG)
## 5X5
![Image alt](https://github.com/NikitenkoNikolai/-Practice_2nd_year_UrFU/tree/main/4/imgs/2.1_5x5.JPG)
## 7X7
![Image alt](https://github.com/NikitenkoNikolai/-Practice_2nd_year_UrFU/tree/main/4/imgs/2.1_7x7.JPG)
## 3X3 AND 7X7
![Image alt](https://github.com/NikitenkoNikolai/-Practice_2nd_year_UrFU/tree/main/4/imgs/2.1_multi.JPG)
## Общий анализ параметров
![Image alt](https://github.com/NikitenkoNikolai/-Practice_2nd_year_UrFU/tree/main/4/imgs/2.1_all.JPG)

# Итог 2.1
## Точность на тестовой выборке:

3x3 ядра : Демонстрируют стабильное и высокое качество обучения, достигая самой высокой точности среди всех моделей. Это связано с тем, что 3x3 фильтры обеспечивают оптимальный баланс между детализацией локальных признаков и вычислительной эффективностью.

5x5 ядра : Показывают хорошую производительность, но немного уступают 3x3 ядрам. Более широкие рецептивные поля позволяют захватывать более глобальные паттерны, однако увеличение размера ядер приводит к росту числа параметров и вычислений, что может снижать скорость обучения.

7x7 ядра : Имеют наибольшие рецептивные поля уже на ранних слоях, что позволяет модели быстрее обнаруживать крупные объекты. Однако из-за значительного количества параметров и потери детализации на начальных этапах точность ниже, чем у 3x3 и 5x5 ядер.

Комбинация разных размеров (1x1 + 3x3) : Обеспечивает гибкость в извлечении признаков благодаря комбинированному подходу. Модель показывает среднюю точность, так как 1x1 свёртки помогают уменьшить количество каналов, а 3x3 — сохраняют детали. Однако её результаты менее стабильны, чем у чистых 3x3 или 5x5 ядер.

## Время обучения:

3x3 ядра : Обучается наиболее быстро благодаря компактным размерам фильтров и меньшему количеству параметров. Это делает модель особенно эффективной для задач с ограниченными ресурсами.

5x5 ядра : Занимает больше времени на обучение, чем 3x3, из-за увеличенного объёма вычислений. Тем не менее, время обучения остаётся приемлемым.

7x7 ядра : Самые медленные в обучении из-за большого количества параметров и вычислений. Рецептивные поля становятся слишком широкими уже на ранних слоях, что требует дополнительных затрат.

Комбинация разных размеров (1x1 + 3x3) : Обучается быстрее, чем 7x7 ядра, но немного медленнее, чем 3x3. Комбинированный подход позволяет снизить общее количество параметров, что ускоряет процесс обучения.
## Рецептивные поля:

3x3 ядра : Рецептивные поля увеличиваются постепенно через несколько слоёв, что позволяет сети лучше улавливать локальные особенности изображения, сохраняя при этом детализацию.

5x5 ядра : Обеспечивают более широкие рецептивные поля уже на начальных слоях, что позволяет модели быстрее захватывать крупные участки изображения. Однако это может привести к потере некоторых мелких деталей.

7x7 ядра : Имеют самые большие рецептивные поля на ранних этапах, что обеспечивает быстрый захват глобальных паттернов. Однако это также вызывает потерю детализации и увеличивает вычислительную нагрузку.

Комбинация разных размеров (1x1 + 3x3) : Сочетание 1x1 и 3x3 свёрток позволяет эффективно регулировать количество каналов и управлять информационным потоком. Это обеспечивает гибкость в извлечении признаков, но требует тонкой настройки для предотвращения переобучения.
## Активации первого слоя:

3x3 ядра : Фильтры хорошо реагируют на края и текстуры, сохраняя при этом структуру исходного изображения. Активации демонстрируют высокую чувствительность к мелким деталям.

5x5 ядра : Активации показывают более широкий охват пространства, что позволяет модели быстрее захватывать крупные паттерны. Однако детализация на начальных слоях ниже, чем у 3x3 ядер.

7x7 ядра : Первые активации имеют очень широкие рецептивные поля, что приводит к потере мелких деталей. Это видно по более размытым и обобщённым картам активаций.

Комбинация разных размеров (1x1 + 3x3) : Комбинированные фильтры демонстрируют гибкость в реакции на различные типы 
признаков. 1x1 свёртки помогают сократить количество каналов, а 3x3 — сохранить детали.

## Общие выводы:
3x3 ядра являются оптимальным выбором для большинства задач классификации изображений. Они обеспечивают высокую точность, низкое время обучения и умеренное количество параметров.
5x5 ядра могут быть полезны, когда требуется быстрый захват крупных паттернов, но они требуют больше вычислительных ресурсов.

7x7 ядра подходят для задач, где важно сразу захватывать большие участки изображения, но их использование должно быть ограничено из-за высокой вычислительной стоимости.
Комбинация разных размеров (1x1 + 3x3) предоставляет гибкость в управлении информацией, но требует тонкой настройки для достижения максимальной эффективности.
# 2.2 Влияние глубины CNN
![Image alt](https://github.com/NikitenkoNikolai/-Practice_2nd_year_UrFU/tree/main/4/imgs/2.2_1.JPG)
![Image alt](https://github.com/NikitenkoNikolai/-Practice_2nd_year_UrFU/tree/main/4/imgs/2.2_2.JPG)
![Image alt](https://github.com/NikitenkoNikolai/-Practice_2nd_year_UrFU/tree/main/4/imgs/2.2_3.JPG)
![Image alt](https://github.com/NikitenkoNikolai/-Practice_2nd_year_UrFU/tree/main/4/imgs/2.2_4.JPG)
# Итог 2.2
## Неглубокая CNN (2 conv слоя)
Модель состоит из двух сверточных слоёв, за которыми следует пулинг и полносвязные слои. Общее количество параметров - около 100 тысяч . Модель обучается быстро и показывает хорошую точность уже на второй эпохе. На тестовой выборке достигнута точность около 98.5% . Градиенты остаются стабильными, vanishing gradients не наблюдается. Feature maps чётко выделяют края и простые формы.

## Средняя CNN (4 conv слоя)
Модель содержит четыре свёрточных слоя с поочерёдным применением MaxPool. Количество параметров увеличивается до примерно 2 миллиона , что заметно замедляет обучение. Точность немного выше, чем у неглубокой сети - около 98.7% . Градиенты начинают ослабевать во внутренних слоях, но не критично. Feature maps становятся более абстрактными и реагируют на комбинации признаков.

## Глубокая CNN (6+ conv слоев)
Модель содержит шесть сверточных слоёв и несколько уровней пулинга. Общее количество параметров превышает 3 миллиона . Обучение занимает значительно больше времени, а точность снижается до 97.2% . Это связано с проблемой vanishing gradients : в первых слоях значения градиентов становятся крайне малыми, что затрудняет обучение. Feature maps на ранних слоях теряют чёткость, так как модель "не успевает" правильно настроить фильтры.

## CNN с Residual связями
ResNet-архитектура использует skip connections, которые позволяют градиентам проходить через несколько слоёв без значительного ослабления. Эта модель имеет около 200 тысяч параметров , обучается быстрее глубокой CNN и достигает самой высокой точности - 99.1% . Градиенты остаются стабильными даже в самых глубоких частях сети. Feature maps сохраняют информативность и чёткость благодаря эффективной передаче информации через residual блоки.

# Вывод
В этой работе я сравнивал разные архитектуры нейросетей для классификации изображений. В целом, CNN показали себя лучше, чем полносвязные сети — они точнее и лучше справляются с изображениями. Простые сверточные сети (SimpleCNN) работают хорошо и быстро, а использование residual-связей помогает обучать даже глубокие сети без потери качества. Однако слишком большая глубина или большие ядра могут ухудшать результаты из-за переобучения или увеличения времени обучения. В будущем можно попробовать ещё больше оптимизировать модель, чтобы добиться лучшего баланса между скоростью и точностью.
