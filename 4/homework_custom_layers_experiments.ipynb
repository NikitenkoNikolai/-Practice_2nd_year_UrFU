{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e683b3-a748-4c7e-bd54-90333c92a3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot([1, 2, 3], [1, 4, 9])\n",
    "plt.title(\"Тестовый график\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3d93f711-db13-48a8-a53d-37038c5c7453",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class MNISTDataset(Dataset):\n",
    "    def __init__(self, train=True, transform=None):\n",
    "        super().__init__()\n",
    "        self.dataset = torchvision.datasets.MNIST(\n",
    "            root='./data', \n",
    "            train=train, \n",
    "            download=True, \n",
    "            transform=transform\n",
    "        )\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.dataset[idx]\n",
    "\n",
    "\n",
    "class CIFARDataset(Dataset):\n",
    "    def __init__(self, train=True, transform=None):\n",
    "        super().__init__()\n",
    "        self.dataset = torchvision.datasets.CIFAR10(\n",
    "            root='./data', \n",
    "            train=train, \n",
    "            download=True, \n",
    "            transform=transform\n",
    "        )\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.dataset[idx]\n",
    "\n",
    "\n",
    "def get_mnist_loaders(batch_size=64):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "    \n",
    "    train_dataset = MNISTDataset(train=True, transform=transform)\n",
    "    test_dataset = MNISTDataset(train=False, transform=transform)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    return train_loader, test_loader\n",
    "\n",
    "\n",
    "def get_cifar_loaders(batch_size=64):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "    ])\n",
    "    \n",
    "    train_dataset = CIFARDataset(train=True, transform=transform)\n",
    "    test_dataset = CIFARDataset(train=False, transform=transform)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    return train_loader, test_loader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "26be60f2-07e8-4eae-948b-8e3f52b4eb16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, 3, stride, 1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, 1, stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, input_channels=1, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(input_channels, 32, 3, 1, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1, 1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "#3x3 ядра\n",
    "class SimpleCNN3x3(nn.Module):\n",
    "    def __init__(self, input_channels=1, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(input_channels, 64, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(128, 256, 3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(2304, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "# 5x5 ядра\n",
    "class SimpleCNN5x5(nn.Module):\n",
    "    def __init__(self, input_channels=1, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(input_channels, 32, 5, padding=2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 5, padding=2)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 5, padding=2)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(1152, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "#7x7 ядра\n",
    "class SimpleCNN7x7(nn.Module):\n",
    "    def __init__(self, input_channels=1, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(input_channels, 16, 7, padding=3)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 7, padding=3)\n",
    "        self.conv3 = nn.Conv2d(32, 64, 7, padding=3)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(576, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "#Комбинация разных размеров (1x1 + 3x3 + 5x5)\n",
    "class SimpleCNNMixed(nn.Module):\n",
    "    def __init__(self, input_channels=1, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(input_channels, 32, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 5, padding=2)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(1152, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "class CNNWithResidual(nn.Module):\n",
    "    def __init__(self, input_channels=1, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(input_channels, 32, 3, 1, 1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        \n",
    "        self.res1 = ResidualBlock(32, 32)\n",
    "        self.res2 = ResidualBlock(32, 64, 2)\n",
    "        self.res3 = ResidualBlock(64, 64)\n",
    "        \n",
    "        self.pool = nn.AdaptiveAvgPool2d((4, 4))\n",
    "        self.fc = nn.Linear(64 * 4 * 4, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.res1(x)\n",
    "        x = self.res2(x)\n",
    "        x = self.res3(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class CIFARCNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, 1, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1, 1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, 1, 1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(128 * 4 * 4, 256)\n",
    "        self.fc2 = nn.Linear(256, num_classes)\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "231527c5-7eb9-4a23-9abe-32cb7fafa9f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FullyConnectedModel(nn.Module):\n",
    "    def __init__(self, config_path=None, input_size=None, num_classes=None, **kwargs):\n",
    "        super().__init__()\n",
    "        \n",
    "        if config_path:\n",
    "            self.config = self.load_config(config_path)\n",
    "        else:\n",
    "            self.config = kwargs\n",
    "\n",
    "        self.input_size = input_size or self.config.get('input_size', 784)\n",
    "        self.num_classes = num_classes or self.config.get('num_classes', 10)\n",
    "\n",
    "        self.layers = self._build_layers()\n",
    "\n",
    "    def load_config(self, config_path):\n",
    "        \"\"\"\n",
    "        Загружает конфигурацию из JSON файла\n",
    "        \"\"\"\n",
    "        with open(config_path, 'r') as f:\n",
    "            return json.load(f)\n",
    "\n",
    "    def _build_layers(self):\n",
    "        layers = []\n",
    "        prev_size = self.input_size\n",
    "\n",
    "        layer_config = self.config.get('layers', [])\n",
    "\n",
    "        for layer_spec in layer_config:\n",
    "            layer_type = layer_spec['type']\n",
    "\n",
    "            match layer_type:\n",
    "                case 'linear':\n",
    "                    out_size = layer_spec['size']\n",
    "                    layers.append(nn.Linear(prev_size, out_size))\n",
    "                    prev_size = out_size\n",
    "\n",
    "                case 'relu':\n",
    "                    layers.append(nn.ReLU())\n",
    "\n",
    "                case 'sigmoid':\n",
    "                    layers.append(nn.Sigmoid())\n",
    "\n",
    "                case 'tanh':\n",
    "                    layers.append(nn.Tanh())\n",
    "\n",
    "                case 'dropout':\n",
    "                    rate = layer_spec.get('rate', 0.5)\n",
    "                    layers.append(nn.Dropout(rate))\n",
    "\n",
    "                case 'batch_norm':\n",
    "                    layers.append(nn.BatchNorm1d(prev_size))\n",
    "\n",
    "                case 'layer_norm':\n",
    "                    layers.append(nn.LayerNorm(prev_size))\n",
    "\n",
    "                case _:\n",
    "                    raise ValueError(f\"Неизвестный тип слоя: {layer_type}\")\n",
    "\n",
    "        # Всегда добавляем финальный слой для классификации\n",
    "        layers.append(nn.Linear(prev_size, self.num_classes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)  # \"выпрямляем\" картинку в вектор\n",
    "        return self.layers(x)\n",
    "\n",
    "# 3.1\n",
    "class CustomConv2d(nn.Module):\n",
    "    # Добавил возможность применения аддитивного шума к входным данным внутри слоя\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, noise_std=0.1):\n",
    "        super(CustomConv2d, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
    "        self.noise_std = noise_std\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.training:\n",
    "            noise = torch.randn_like(x) * self.noise_std\n",
    "            x = x + noise\n",
    "        return self.conv(x)\n",
    "    \n",
    "class SpatialAttention(nn.Module):\n",
    "    def __init__(self, kernel_size=7):\n",
    "        super(SpatialAttention, self).__init__()\n",
    "        self.conv = nn.Conv2d(2, 1, kernel_size, padding=kernel_size//2)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
    "        x = torch.cat([avg_out, max_out], dim=1)\n",
    "        x = self.conv(x)\n",
    "        return self.sigmoid(x)\n",
    "    \n",
    "class CustomReLU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomReLU, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.input = x\n",
    "        return x.clamp(min=0)\n",
    "\n",
    "    def backward(self, grad_output):\n",
    "        # Обычный ReLU: градиент пропускается, если input > 0\n",
    "        grad_input = grad_output.clone()\n",
    "        grad_input[self.input < 0] = 0\n",
    "        return grad_input\n",
    "    \n",
    "class CustomAdaptiveAvgPool2d(nn.Module):\n",
    "    def __init__(self, output_size):\n",
    "        super(CustomAdaptiveAvgPool2d, self).__init__()\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        bs, c, h, w = x.size()\n",
    "        oh, ow = self.output_size\n",
    "        sh, sw = h // oh, w // ow\n",
    "        x = x.view(bs, c, oh, sh, ow, sw)\n",
    "        x = x.mean([3, 5])  # усреднение по блокам\n",
    "        return x\n",
    "    \n",
    "# 3.2 \n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion * planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion * planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "class BottleneckBlock(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BottleneckBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, self.expansion * planes, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(self.expansion * planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion * planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion * planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "    \n",
    "class WideResidualBlock(nn.Module):\n",
    "    #используем увеличенное количество фильтров в каждом слое\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1, widen_factor=2):\n",
    "        super(WideResidualBlock, self).__init__()\n",
    "        planes = int(planes * widen_factor)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != planes * self.expansion:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, planes * self.expansion, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * self.expansion)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1bd14bf5-239f-413f-8b1c-121f6f86a986",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config_3_layer = {\n",
    "    \"input_size\": 784,\n",
    "    \"num_classes\": 10,\n",
    "    \"layers\": [\n",
    "        {\"type\": \"linear\", \"size\": 512},\n",
    "        {\"type\": \"relu\"},\n",
    "        {\"type\": \"batch_norm\"},\n",
    "\n",
    "        {\"type\": \"linear\", \"size\": 256},\n",
    "        {\"type\": \"relu\"},\n",
    "        {\"type\": \"dropout\", \"rate\": 0.4}\n",
    "    ]\n",
    "}\n",
    "config_7_layer = {\n",
    "    \"input_size\": 3072,\n",
    "    \"num_classes\": 10,\n",
    "    \"layers\": [\n",
    "        {\"type\": \"linear\", \"size\": 512},\n",
    "        {\"type\": \"relu\"},\n",
    "        {\"type\": \"linear\", \"size\": 256},\n",
    "        {\"type\": \"relu\"},\n",
    "        {\"type\": \"linear\", \"size\": 128},\n",
    "        {\"type\": \"relu\"},\n",
    "        {\"type\": \"linear\", \"size\": 64},\n",
    "        {\"type\": \"relu\"},\n",
    "        {\"type\": \"linear\", \"size\": 32},\n",
    "        {\"type\": \"relu\"},\n",
    "    ]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "261cd658-7d04-4f9e-a55b-940f52fde764",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Создаем функцию для grad flow \n",
    "def get_gradient_flow(model):\n",
    "    avg_grads = []\n",
    "    \n",
    "    for name, param in model.named_parameters():\n",
    "        if 'weight' in name and param.grad is not None:\n",
    "            avg_grad = param.grad.abs().mean().item()#Считаем среднее значение градиента по модулю\n",
    "            avg_grads.append((name, avg_grad))\n",
    "    \n",
    "    return avg_grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a04f30ab-a917-41ca-83e9-2f828dd665f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_epoch(model, data_loader, criterion, optimizer=None, device='cpu', is_test=False):\n",
    "    if is_test:\n",
    "        model.eval()\n",
    "    else:\n",
    "        model.train()\n",
    "    \n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(tqdm(data_loader)):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        if not is_test and optimizer is not None:\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        if not is_test and optimizer is not None:\n",
    "            loss.backward()   \n",
    "            optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "        total += target.size(0)\n",
    "    \n",
    "    return total_loss / len(data_loader), correct / total\n",
    "\n",
    "\n",
    "def train_model(model, train_loader, test_loader, epochs=10, lr=0.001, device='cpu'):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    train_losses, train_accs = [], []\n",
    "    test_losses, test_accs = [], []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        train_loss, train_acc = run_epoch(model, train_loader, criterion, optimizer, device, is_test=False)\n",
    "        test_loss, test_acc = run_epoch(model, test_loader, criterion, None, device, is_test=True)\n",
    "        if epochs % 2 == 0:\n",
    "            grads = get_gradient_flow(model)# вызов градиентов \n",
    "            for name, grad in grads:\n",
    "                print(f\"{name}: {grad:.6f}\")\n",
    "                \n",
    "        train_losses.append(train_loss)\n",
    "        train_accs.append(train_acc)\n",
    "        test_losses.append(test_loss)\n",
    "        test_accs.append(test_acc)\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{epochs}:')\n",
    "        print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}')\n",
    "        print(f'Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}')\n",
    "        print('-' * 50)\n",
    "    \n",
    "    return {\n",
    "        'train_losses': train_losses,\n",
    "        'train_accs': train_accs,\n",
    "        'test_losses': test_losses,\n",
    "        'test_accs': test_accs\n",
    "    } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "420bae04-e17c-4809-bcb8-725c044cd1fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_training_history(history):\n",
    "    \"\"\"Визуализирует историю обучения\"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    \n",
    "    ax1.plot(history['train_losses'], label='Train Loss')\n",
    "    ax1.plot(history['test_losses'], label='Test Loss')\n",
    "    ax1.set_title('Loss')\n",
    "    ax1.legend()\n",
    "    \n",
    "    ax2.plot(history['train_accs'], label='Train Acc')\n",
    "    ax2.plot(history['test_accs'], label='Test Acc')\n",
    "    ax2.set_title('Accuracy')\n",
    "    ax2.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def count_parameters(model):\n",
    "    \"\"\"Подсчитывает количество параметров модели\"\"\"\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "def save_model(model, path):\n",
    "    \"\"\"Сохраняет модель\"\"\"\n",
    "    torch.save(model.state_dict(), path)\n",
    "\n",
    "\n",
    "def load_model(model, path):\n",
    "    \"\"\"Загружает модель\"\"\"\n",
    "    model.load_state_dict(torch.load(path))\n",
    "    return model\n",
    "\n",
    "\n",
    "def compare_models(fc_history, cnn_history):\n",
    "    \"\"\"Сравнивает результаты полносвязной и сверточной сетей\"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    \n",
    "    ax1.plot(fc_history['test_accs'], label='FC Network', marker='o')\n",
    "    ax1.plot(cnn_history['test_accs'], label='CNN', marker='s')\n",
    "    ax1.set_title('Test Accuracy Comparison')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True)\n",
    "    \n",
    "    ax2.plot(fc_history['test_losses'], label='FC Network', marker='o')\n",
    "    ax2.plot(cnn_history['test_losses'], label='CNN', marker='s')\n",
    "    ax2.set_title('Test Loss Comparison')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show() \n",
    "\n",
    "def compute_confusion_matrix(model, data_loader, device='cpu'):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    with torch.no_grad():\n",
    "        for data, target in data_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            preds = output.argmax(dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_targets.extend(target.cpu().numpy())\n",
    "\n",
    "    cm = confusion_matrix(all_targets, all_preds)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.show()\n",
    "def visualize_first_layer_activations(model, data_loader, device, title=\"Model\"):\n",
    "    model.eval()\n",
    "    # Берём первую batch для визуализации\n",
    "    data, _ = next(iter(data_loader))\n",
    "    data = data.to(device)\n",
    "    \n",
    "    # Получаем выход первого сверточного слоя\n",
    "    first_conv_layer = None\n",
    "    for layer in model.children():\n",
    "        if isinstance(layer, nn.Conv2d):\n",
    "            first_conv_layer = layer\n",
    "            break\n",
    "    \n",
    "    if first_conv_layer is None:\n",
    "        print(\"Нет сверточных слоев в модели.\")\n",
    "        return\n",
    "\n",
    "    # Forward до первого сверточного слоя\n",
    "    with torch.no_grad():\n",
    "        activations = first_conv_layer(data)\n",
    "\n",
    "    # Берём первую картинку из батча\n",
    "    img = data[0].cpu().numpy().transpose((1, 2, 0))  # CHW -> HWC\n",
    "    img = (img - img.min()) / (img.max() - img.min())  # Нормируем\n",
    "\n",
    "    # Визуализация\n",
    "    fig, axes = plt.subplots(1, activations.size(1) + 1, figsize=(15, 3))\n",
    "    axes[0].imshow(img.squeeze(), cmap='gray')\n",
    "    axes[0].set_title('Input Image')\n",
    "    axes[0].axis('off')\n",
    "\n",
    "    for i in range(activations.size(1)):\n",
    "        act = activations[0, i].cpu().numpy()\n",
    "        act = (act - act.min()) / (act.max() - act.min())\n",
    "        axes[i + 1].imshow(act, cmap='viridis')\n",
    "        axes[i + 1].set_title(f'Ch {i+1}')\n",
    "        axes[i + 1].axis('off')\n",
    "\n",
    "    plt.suptitle(f\"{title} - First Layer Activations\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "def compare_kernel_results(results):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Сравнение точности\n",
    "    for name in results:\n",
    "        ax1.plot(results[name]['history']['test_accs'], label=name)\n",
    "    ax1.set_title('Test Accuracy Comparison')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Accuracy')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True)\n",
    "\n",
    "    # Сравнение времени обучения\n",
    "    names = list(results.keys())\n",
    "    times = [results[name]['time'] / 60 for name in names]  # в минутах\n",
    "    ax2.bar(names, times)\n",
    "    ax2.set_title('Training Time (minutes)')\n",
    "    ax2.set_ylabel('Time (min)')\n",
    "    ax2.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8e8726-411e-45cc-9cce-f575ab0283d2",
   "metadata": {},
   "source": [
    "# Задание 3: Кастомные слои и эксперименты"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b01c40-a232-4ef1-9405-449b3866a6e7",
   "metadata": {},
   "source": [
    "# 3.1 Реализация кастомных слоев\n",
    "## Кастомный сверточный слой с дополнительной логикой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a2c750f8-20f8-465a-8ddc-2841d8dd1217",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер кастомного сверточного слоя: torch.Size([1, 16, 32, 32])\n",
      "Размер стандартного сверточного слоя: torch.Size([1, 16, 32, 32])\n",
      "Выводы совпадают или нет?: False\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1, 3, 32, 32)  # batch, channels, height, width\n",
    "\n",
    "custom_conv = CustomConv2d(3, 16, 3, padding=1)\n",
    "standard_conv = nn.Conv2d(3, 16, 3, padding=1)\n",
    "y_custom = custom_conv(x)\n",
    "y_standard = standard_conv(x)\n",
    "\n",
    "print(\"Размер кастомного сверточного слоя:\", y_custom.shape)\n",
    "print(\"Размер стандартного сверточного слоя:\", y_standard.shape)\n",
    "print(\"Выводы совпадают или нет?:\", torch.allclose(y_custom, y_standard))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62706a2f-35c4-4023-8f0c-7d61d001a5ac",
   "metadata": {},
   "source": [
    "Положительное:\n",
    "Архитектура слоя корректна с точки зрения размерностей : кастомный слой возвращает тензор нужной формы.\n",
    "Отрицательное:\n",
    "Значения не совпадают, а значит, что мне удалось создать свой сверточный слой, который отличается от стандартного, так как в моем я добавляю также шумы в слое"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1efeaacb-8f78-4ad2-ab9a-65f1848f3cdd",
   "metadata": {},
   "source": [
    "## Attention механизм"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0c30054e-98e7-4a45-83fd-5fff01321e3c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер выхода: torch.Size([1, 1, 32, 32])\n",
      "Минимальное значение маски: 0.30229032039642334\n",
      "Максимальное значение маски: 0.8292129635810852\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1, 3, 32, 32)\n",
    "attention_layer = SpatialAttention(kernel_size=7)\n",
    "# Применение слоя\n",
    "output = attention_layer(x)\n",
    "\n",
    "print(\"Размер выхода:\", output.shape)\n",
    "print(\"Минимальное значение маски:\", output.min().item())\n",
    "print(\"Максимальное значение маски:\", output.max().item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af9d220-a7f4-4566-b509-48b744bde31a",
   "metadata": {},
   "source": [
    "Судя по результатам все работает корректно. \n",
    "Размер выхода совпадает с ожидаемым (1, 1, 32, 32), значения маски лежат в диапазоне сигмоиды (от ~0.3 до ~0.8). В отличие от стандартных механизмов, мой фокусируется только на пространственных признаках, что выходит быстрее, но менее информативным, так как не учитывает важность всех каналов."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a23f6c8-f647-4964-af32-26adeb0d2a0c",
   "metadata": {},
   "source": [
    "## Кастомная функция активации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0f16fb33-2616-4130-bb66-862836ae3221",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Кастомный ReLU tensor([0.0000, 0.8280, 0.6459, 0.1727, 0.0000], grad_fn=<ClampBackward1>)\n",
      "Торчевский ReLU tensor([0.0000, 0.8280, 0.6459, 0.1727, 0.0000], grad_fn=<ReluBackward0>)\n",
      "Результаты совпадают?  True\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(5, requires_grad=True)\n",
    "y_custom = CustomReLU().forward(x)\n",
    "y_torch = torch.relu(x)\n",
    "\n",
    "print(\"Кастомный ReLU\", y_custom)\n",
    "print(\"Торчевский ReLU\", y_torch)\n",
    "print(\"Результаты совпадают? \", torch.allclose(y_custom, y_torch))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32148334-fb58-4bce-bd27-727d26c22894",
   "metadata": {},
   "source": [
    "Кастомная реализация CustomReLU возвращает те же значения, что и стандартный torch.relu, о чём свидетельствует результат torch.allclose = True. Разница только в методе вычисления градиентов (ClampBackward1 и ReLUBackward0). В целом, по выходу функции моя реализация эквивалентна стандартной."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb02406-b235-4038-bf92-19836f3d006a",
   "metadata": {},
   "source": [
    "## Кастомный pooling слой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d860cdd0-3d62-4d74-8f2a-d90adead744c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер выхода кастомного слоя: torch.Size([1, 3, 4, 4])\n",
      "Размер выхода стандартного слоя: torch.Size([1, 3, 4, 4])\n",
      "Выводы совпадают или нет?: True\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1, 3, 32, 32)\n",
    "\n",
    "custom_pool = CustomAdaptiveAvgPool2d(output_size=(4, 4))\n",
    "output_custom = custom_pool(x)\n",
    "\n",
    "standard_pool = nn.AdaptiveAvgPool2d(output_size=(4, 4))\n",
    "output_standard = standard_pool(x)\n",
    "\n",
    "print(\"Размер выхода кастомного слоя:\", output_custom.shape)\n",
    "print(\"Размер выхода стандартного слоя:\", output_standard.shape)\n",
    "print(\"Выводы совпадают или нет?:\", torch.allclose(output_custom, output_standard))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c003067-b9a6-44d0-a8b4-b86bdb5d0268",
   "metadata": {},
   "source": [
    "Кастомный pooling слой корректно реализует функционал адаптивного усредняющего пулинга и возвращает выход того же размера что и стандартный. Результаты работы слоёв совпадают по значениям что подтверждает корректность реализации. По функциональности и производительности он эквивалентен стандартному слою но при этом даёт возможность модификации логики, что круто"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934fd9b9-8536-4025-b96c-a6cfe777b704",
   "metadata": {},
   "source": [
    "# 3.2 Эксперименты с Residual блоками"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2a7c66-85b4-4810-9bcf-a9944952d90f",
   "metadata": {},
   "source": [
    "## Базовый Residual блок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "7843291e-74d3-4fe7-89ad-772b6e6dc025",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер выхода: torch.Size([1, 64, 32, 32])\n",
      "Количество параметров в BasicBlock: 73984\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1, 64, 32, 32)\n",
    "block = BasicBlock(64, 64)\n",
    "output = block(x)\n",
    "\n",
    "print(\"Размер выхода:\", output.shape)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(\"Количество параметров в BasicBlock:\", count_parameters(block))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3bc474-60af-4861-abaf-f16fd5f7cab7",
   "metadata": {},
   "source": [
    "BasicBlock корректно обработал входной тензор и вернул выход той же размерности (1, 64, 32, 32) что и ожидалось. Количество обучаемых параметров в блоке составило 73984 что соответствует ожиданиям для двух сверточных слоёв с batch нормализацией. Блок стабильно сохраняет размерность карт признаков и имеет разумное количество параметров подходящее для средних сетей. Это делает его устойчивым к переобучению"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19186060-9c8f-4beb-821e-77798f0654e2",
   "metadata": {},
   "source": [
    "## Bottleneck Residual блок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f0828bf9-036e-4659-b2dc-ac3fbab15521",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер выхода: torch.Size([1, 256, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1, 64, 32, 32)\n",
    "block = BottleneckBlock(64, 64)\n",
    "output = block(x)\n",
    "print(\"Размер выхода:\", output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "b6dab5ee-e74b-449e-8c25-fd0ca89fa70f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество параметров в BottleneckBlock: 75008\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(\"Количество параметров в BottleneckBlock:\", count_parameters(block))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4676b9dc-34a0-433b-a77d-c4d2d94d05c5",
   "metadata": {},
   "source": [
    "BottleneckBlock корректно обработал входной тензор и увеличил количество каналов с 64 до 256 что соответствует ожидаемому поведению этого типа блока. Количество обучаемых параметров составило 75008 что оказалось меньше чем у BasicBlock в предыдущем задании из-за более эффективной архитектуры с узкими промежуточными слоями. Блок сохранил пространственные размеры изображения и показал стабильное поведение при прямом проходе что делает его подходящим для построения глубоких сетей с residual связями."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1593d6-97ca-468d-98b6-ed6d6d004bb4",
   "metadata": {},
   "source": [
    "## Wide Residual блок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "886ee4d5-30fc-4fa4-bd7f-31eeb8282662",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер выхода: torch.Size([1, 128, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1, 64, 32, 32)\n",
    "block = WideResidualBlock(64, 64, widen_factor=2)\n",
    "output = block(x)\n",
    "print(\"Размер выхода:\", output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "9e813803-a9c3-4f69-9884-b66a909a4682",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество параметров в WideResidualBlock: 230144\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(\"Количество параметров в WideResidualBlock:\", count_parameters(block))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81af29a-266a-41b5-b875-abceb115e1cf",
   "metadata": {},
   "source": [
    "WideResidualBlock корректно обработал входной тензор и увеличил количество каналов с 64 до 128 за счёт параметра widen_factor=2 что соответствует ожидаемой работе широкого residual блока. Количество обучаемых параметров составило 230144 что значительно превышает BasicBlock и даже BottleneckBlock из-за увеличенных слоёв. Это делает WideResidualBlock более ёмким по памяти но потенциально способным к лучшему представлению признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bed272-e695-4f32-8d52-ffaa49d1b8af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (newenv)",
   "language": "python",
   "name": "newenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
